"""Reports to aide corpus analysis."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/57_report.ipynb.

# %% auto 0
__all__ = ['Report']

# %% ../nbs/57_report.ipynb 3
import time
from fastcore.basics import patch

# %% ../nbs/57_report.ipynb 4
from .result import Result
from .core import PAGE_SIZE
from .corpus import Corpus
from .frequency import Frequency
from .ngrams import Ngrams
from .concordance import Concordance


# %% ../nbs/57_report.ipynb 5
class Report:
	"""Represention of a text data, with methods to load and save a corpus and to do corpus linguistic analysis of the texts."""
	
	def __init__(self, 
				corpus # Corpus instance
				):
		# information about corpus
		self.corpus = corpus
		self.frequency_ = Frequency(corpus)
		self.ngrams_ = Ngrams(corpus)
		self.concordance_ = Concordance(corpus)



# %% ../nbs/57_report.ipynb 9
@patch
def frequencies(self: Report,
				normalize_by:int=1000000, # normalize frequencies by a number (e.g. 10000)
				page_size:int=PAGE_SIZE, # number of rows to return
				page_current:int=1, # current page
				show_token_id:bool=False, # show token_id in output
				exclude_punctuation:bool=True, # exclude punctuation tokens
				exclude_spaces:bool=True # exclude space tokens
				) -> Result: # return a Result object with the frequency table
	""" Report frequent tokens. """
	return self.frequency_.frequencies(normalize_by=normalize_by, page_size=page_size, page_current=page_current, show_token_id=show_token_id, exclude_punctuation=exclude_punctuation, exclude_spaces=exclude_spaces)

# %% ../nbs/57_report.ipynb 11
@patch
def ngrams(self: Report, 
		   token_str: str, # token string to get ngrams for 
		   ngram_length:int = 2, # length of ngram
		   ngram_word_position:str = 'LEFT', # specify if token sequence is on LEFT, RIGHT, or MIDDLE of ngrams
		   page_size:int = PAGE_SIZE, # number of results to display per results page 
		   page_current:int = 0, # current page of results
		   show_all_columns:bool = False, # return raw df with all columns or just ngram and frequency
		   use_cache:bool = True # retrieve the results from cache if available
		   ) -> Result: # return a Result object with ngram data
	""" Report ngrams for a token string. """
	return self.ngrams_.ngrams(token_str, ngram_length=ngram_length, ngram_word_position=ngram_word_position, page_size=page_size, page_current=page_current, show_all_columns=show_all_columns, use_cache=use_cache)

# %% ../nbs/57_report.ipynb 13
@patch
def concordance(self: Report, 
				token_str: str, # token string to get concordance for 
				context_words:int = 5, # number of words to show on left and right of token string
				order:str='1R2R3R', # order of sort columns
				page_size:int=PAGE_SIZE, # number of results to display per results page
				page_current:int=0, # current page of results
				show_all_columns:bool = False, # df with all columns or just essentials
				use_cache:bool = True # retrieve the results from cache if available
				) -> Result: # concordance report results
	""" Report concordance for a token string. """
	return self.concordance_.concordance(token_str, context_words=context_words, order=order, page_size=page_size, page_current=page_current, show_all_columns=show_all_columns, use_cache=use_cache)

