# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/70_frequency.ipynb.

# %% auto 0
__all__ = ['Frequency']

# %% ../nbs/70_frequency.ipynb 3
import time
import polars as pl
from fastcore.basics import patch

# %% ../nbs/70_frequency.ipynb 4
from .corpus import Corpus
from .result import Result
from .core import logger, PAGE_SIZE

# %% ../nbs/70_frequency.ipynb 5
class Frequency:
	""" Class for frequency analysis reporting """
	def __init__(self,
			  corpus:Corpus # Corpus instance
			  ): 
		self.corpus = corpus


# %% ../nbs/70_frequency.ipynb 6
@patch
def frequencies(self: Frequency,
				n:int=PAGE_SIZE, # number of rows to return
				normalize_by:int=1000000, # normalize frequencies by a number (e.g. 10000)
				sort_by='frequency', # TODO - check if needed
				show_token_id:bool=False, # show token_id in output
				exclude_punctuation:bool=True, # exclude punctuation tokens
				exclude_spaces:bool=True # exclude space tokens
				) -> Result: # return a Result object with the frequency table
	""" Report frequent tokens. """
	# TODO - add in restrict_to and exclude options - latter is for stopword removal
	
	start_time = time.time()
	self.corpus._init_frequency_table()

	columns = ['rank', 'token', 'frequency']
	if show_token_id == True:
		columns = ['rank', 'token_id', 'token', 'frequency']

	count_tokens = self.corpus.token_count
	if exclude_punctuation and exclude_spaces:
		count_tokens = self.corpus.word_token_count
	elif exclude_punctuation:
		count_tokens = self.corpus.word_token_count + len(self.corpus.punct_tokens)
	elif exclude_spaces:
		count_tokens = self.corpus.word_token_count + len(self.corpus.space_tokens)		

	# if a number is passed then normalize by that number
	if type(normalize_by) != int:
		raise ValueError('normalize_by must be an integer, e.g. 1000000 or 10000')
	self.corpus.frequency_table = self.corpus.frequency_table.with_columns((pl.col('frequency') * normalize_by / count_tokens).alias('normalized_frequency'))
	columns.append('normalized_frequency')

	# TODO - work out what doing with sort_by
	# if sort_by in ['frequency', 'normalized_frequency']:
	# 	self.frequency_table = self.frequency_table.sort(sort_by, descending=True)
	# 	self.frequency_table = self.frequency_table.drop('rank').with_row_index(name='rank', offset=1)

	formatted_data = []
	if normalize_by is not None:
		formatted_data.append(f'Normalized Frequency is per {normalize_by:,.0f} tokens')

	logger.info(f'Frequencies report time: {(time.time() - start_time):.5f} seconds')

	df = self.corpus.frequency_table.sort('frequency', descending=True)
	if exclude_punctuation:
		df = df.filter(pl.col('is_punct') == False)
	if exclude_spaces:
		df = df.filter(pl.col('is_space') == False)
	if n:
		df = df[columns].head(n)
	else:
		df = df[columns]
	# remove rows with is_punct or is_space columns set to True
	df = df.drop('rank').with_row_index(name='rank', offset=1)
	return Result(type = 'frequencies', df=df, title='Frequencies', description='Frequencies of tokens in the corpus', summary_data={}, formatted_data=formatted_data)

