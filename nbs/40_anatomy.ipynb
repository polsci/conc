{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6713975",
   "metadata": {},
   "source": [
    "# Anatomy of a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63cdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import polars as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad510588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from conc.corpus import Corpus, CorpusMetadata\n",
    "import msgspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3a11e",
   "metadata": {},
   "source": [
    "A Conc corpus is a directory containing specific files as follows:\n",
    "\n",
    "```\n",
    "corpus-name.corpus/\n",
    "\tREADME.md - Human readable information about the corpus to aide distribution\n",
    "\tcorpus.json - Machine readable information about the corpus, including name, description, various summary statistics, and models used to build the corpus\n",
    "\tvocab.parquet - A table mapping token strings to token IDs and frequency information\n",
    "\ttokens.parquet - A table with indices based on token positions used to query the corpus with tokens represented by numeric IDs\n",
    "\tmetadata.parquet - A table with metadata for each document (if there is any)\n",
    "```\n",
    "\n",
    "Note: by default the library creates a directory with the `.corpus` suffix. This is not necessary, but this makes corpora on your filesystem easier to find or identify.\n",
    "\n",
    "To distribute a corpus, send a zip of the directory for others to extract or just share the directory as-is.\n",
    "\n",
    "Below is more information about each file. You can obviously work with a corpus using Conc, but you can work with the processed corpus `.parquet` files directly using the `polars` library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219163c",
   "metadata": {},
   "source": [
    "### README.md\n",
    "\n",
    "Below is an example of the README.md file generated by the Conc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24402bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96baf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "source_path = f'{os.environ.get(\"HOME\")}/data/'\n",
    "save_path = f'{os.environ.get(\"HOME\")}/data/conc-test-corpora/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "brown = Corpus().load(f'{save_path}/brown.corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4f1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"alert alert-block alert-success\">\n",
       "\n",
       "## Brown Corpus\n",
       "\n",
       "### About\n",
       "\n",
       "This directory contains a corpus created using the [Conc](https://github.com/polsci/conc) Python library. \n",
       "\n",
       "### Corpus Information\n",
       "\n",
       "A Standard Corpus of Present-Day Edited American English, for use with Digital Computers. by W. N. Francis and H. Kucera (1964) Department of Linguistics, Brown University Providence, Rhode Island, USA Revised 1971, Revised and Amplified 1979 http://www.hit.uib.no/icame/brown/bcm.html\n",
       "\n",
       "Date created: 2025-05-28 14:49:02  \n",
       "Document count: 500  \n",
       "Token count: 1140905  \n",
       "Word token count: 980144  \n",
       "Unique tokens: 42937  \n",
       "Unique word tokens: 42907  \n",
       "Conc Version Number: 0.0.1  \n",
       "spaCy model: en_core_web_sm, version 3.8.0  \n",
       "\n",
       "### Using this corpus\n",
       "\n",
       "Conc can be installed [via pip]():  \n",
       "```\n",
       "pip install conc\n",
       "```\n",
       "Documentation and tutorials to get you started with Conc are available:\n",
       "[Conc Documentation](https://geoffford.nz/conc)\n",
       "\n",
       "### Cite Conc\n",
       "\n",
       "If you use Conc in your work, please cite it as follows:\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: true\n",
    "with open(f'{brown.corpus_path}/README.md', 'rb') as f:\n",
    "    markdown = '<div class=\"alert alert-block alert-success\">\\n\\n' + f.read().decode('utf-8') + '\\n'\n",
    "    markdown = markdown.replace('\\n#', '\\n##') # making headings smaller for display\n",
    "    markdown += '</div>'\n",
    "    display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee41ffa",
   "metadata": {},
   "source": [
    "### corpus.json file\n",
    "\n",
    "Below is the schema of the `corpus.json` file showing metadata saved with a corpus. These are loaded by Conc as attributes using `Corpus.load` or are created when you build a corpus using `Corpus.build_from_files` or `Corpus.build_from_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bcca47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': {'type': 'string'},\n",
       " 'description': {'type': 'string'},\n",
       " 'slug': {'type': 'string'},\n",
       " 'conc_version': {'type': 'string'},\n",
       " 'document_count': {'type': 'integer'},\n",
       " 'token_count': {'type': 'integer'},\n",
       " 'word_token_count': {'type': 'integer'},\n",
       " 'punct_token_count': {'type': 'integer'},\n",
       " 'space_token_count': {'type': 'integer'},\n",
       " 'unique_tokens': {'type': 'integer'},\n",
       " 'unique_word_tokens': {'type': 'integer'},\n",
       " 'date_created': {'type': 'string'},\n",
       " 'EOF_TOKEN': {'type': 'integer'},\n",
       " 'SPACY_EOF_TOKEN': {'type': 'integer'},\n",
       " 'SPACY_MODEL': {'type': 'string'},\n",
       " 'SPACY_MODEL_VERSION': {'type': 'string'},\n",
       " 'punct_tokens': {'type': 'array', 'items': {'type': 'integer'}},\n",
       " 'space_tokens': {'type': 'array', 'items': {'type': 'integer'}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: true\n",
    "properties = msgspec.json.schema(CorpusMetadata)['$defs']['CorpusMetadata']['properties']\n",
    "display(properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c199320",
   "metadata": {},
   "source": [
    "### vocab.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb32cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>rank</th><th>token_id</th><th>token</th><th>frequency_lower</th><th>frequency_orth</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>1</td><td>22848</td><td>&quot;the&quot;</td><td>63516</td><td>62473</td><td>false</td><td>false</td></tr><tr><td>2</td><td>8128</td><td>&quot;,&quot;</td><td>58331</td><td>58331</td><td>true</td><td>false</td></tr><tr><td>3</td><td>38309</td><td>&quot;.&quot;</td><td>49907</td><td>49907</td><td>true</td><td>false</td></tr><tr><td>4</td><td>2739</td><td>&quot;of&quot;</td><td>36321</td><td>36122</td><td>false</td><td>false</td></tr><tr><td>5</td><td>7126</td><td>&quot;and&quot;</td><td>27787</td><td>27633</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────┬──────────┬───────┬─────────────────┬────────────────┬──────────┬──────────┐\n",
       "│ rank ┆ token_id ┆ token ┆ frequency_lower ┆ frequency_orth ┆ is_punct ┆ is_space │\n",
       "╞══════╪══════════╪═══════╪═════════════════╪════════════════╪══════════╪══════════╡\n",
       "│ 1    ┆ 22848    ┆ the   ┆ 63516           ┆ 62473          ┆ false    ┆ false    │\n",
       "│ 2    ┆ 8128     ┆ ,     ┆ 58331           ┆ 58331          ┆ true     ┆ false    │\n",
       "│ 3    ┆ 38309    ┆ .     ┆ 49907           ┆ 49907          ┆ true     ┆ false    │\n",
       "│ 4    ┆ 2739     ┆ of    ┆ 36321           ┆ 36122          ┆ false    ┆ false    │\n",
       "│ 5    ┆ 7126     ┆ and   ┆ 27787           ┆ 27633          ┆ false    ┆ false    │\n",
       "└──────┴──────────┴───────┴─────────────────┴────────────────┴──────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: true\n",
    "display(pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').head(5).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b388d",
   "metadata": {},
   "source": [
    "Explain how frequency stored - i.e. with different word forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>rank</th><th>token_id</th><th>token</th><th>frequency_lower</th><th>frequency_orth</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>1</td><td>22848</td><td>&quot;the&quot;</td><td>63516</td><td>62473</td><td>false</td><td>false</td></tr><tr><td>99</td><td>15682</td><td>&quot;The&quot;</td><td>null</td><td>1043</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────┬──────────┬───────┬─────────────────┬────────────────┬──────────┬──────────┐\n",
       "│ rank ┆ token_id ┆ token ┆ frequency_lower ┆ frequency_orth ┆ is_punct ┆ is_space │\n",
       "╞══════╪══════════╪═══════╪═════════════════╪════════════════╪══════════╪══════════╡\n",
       "│ 1    ┆ 22848    ┆ the   ┆ 63516           ┆ 62473          ┆ false    ┆ false    │\n",
       "│ 99   ┆ 15682    ┆ The   ┆ null            ┆ 1043           ┆ false    ┆ false    │\n",
       "└──────┴──────────┴───────┴─────────────────┴────────────────┴──────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: true\n",
    "display(pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').filter(pl.col('token').str.to_lowercase() == 'the').head(5).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ba1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>rank</th><th>token_id</th><th>token</th><th>frequency_lower</th><th>frequency_orth</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>328</td><td>11309</td><td>&quot;government&quot;</td><td>438</td><td>284</td><td>false</td><td>false</td></tr><tr><td>644</td><td>55689</td><td>&quot;Government&quot;</td><td>null</td><td>154</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────┬──────────┬────────────┬─────────────────┬────────────────┬──────────┬──────────┐\n",
       "│ rank ┆ token_id ┆ token      ┆ frequency_lower ┆ frequency_orth ┆ is_punct ┆ is_space │\n",
       "╞══════╪══════════╪════════════╪═════════════════╪════════════════╪══════════╪══════════╡\n",
       "│ 328  ┆ 11309    ┆ government ┆ 438             ┆ 284            ┆ false    ┆ false    │\n",
       "│ 644  ┆ 55689    ┆ Government ┆ null            ┆ 154            ┆ false    ┆ false    │\n",
       "└──────┴──────────┴────────────┴─────────────────┴────────────────┴──────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: true\n",
    "display(pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').filter(pl.col('token').str.to_lowercase() == 'government').head(5).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776487e",
   "metadata": {},
   "source": [
    "### tokens.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cd68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>position</th><th>orth_index</th><th>lower_index</th><th>token2doc_index</th></tr></thead><tbody><tr><td>99</td><td>46333</td><td>46333</td><td>-1</td></tr><tr><td>100</td><td>27276</td><td>27276</td><td>0</td></tr><tr><td>101</td><td>15682</td><td>22848</td><td>0</td></tr><tr><td>102</td><td>4361</td><td>41672</td><td>0</td></tr><tr><td>103</td><td>14610</td><td>29725</td><td>0</td></tr><tr><td>104</td><td>54713</td><td>49998</td><td>0</td></tr><tr><td>105</td><td>45742</td><td>19078</td><td>0</td></tr><tr><td>106</td><td>53250</td><td>53250</td><td>0</td></tr><tr><td>107</td><td>8699</td><td>35796</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────────┬────────────┬─────────────┬─────────────────┐\n",
       "│ position ┆ orth_index ┆ lower_index ┆ token2doc_index │\n",
       "╞══════════╪════════════╪═════════════╪═════════════════╡\n",
       "│ 99       ┆ 46333      ┆ 46333       ┆ -1              │\n",
       "│ 100      ┆ 27276      ┆ 27276       ┆ 0               │\n",
       "│ 101      ┆ 15682      ┆ 22848       ┆ 0               │\n",
       "│ 102      ┆ 4361       ┆ 41672       ┆ 0               │\n",
       "│ 103      ┆ 14610      ┆ 29725       ┆ 0               │\n",
       "│ 104      ┆ 54713      ┆ 49998       ┆ 0               │\n",
       "│ 105      ┆ 45742      ┆ 19078       ┆ 0               │\n",
       "│ 106      ┆ 53250      ┆ 53250       ┆ 0               │\n",
       "│ 107      ┆ 8699       ┆ 35796       ┆ 0               │\n",
       "└──────────┴────────────┴─────────────┴─────────────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: true\n",
    "pl.scan_parquet(f'{brown.corpus_path}/tokens.parquet').with_row_index('position').filter(pl.col('position').is_between(99, 107)).collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e7caf",
   "metadata": {},
   "source": [
    "TODO Explain this token2doc_index -1 above and various other fields mapped below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d4576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>position</th><th>orth_index</th><th>lower_index</th><th>token2doc_index</th><th>token</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>99</td><td>46333</td><td>46333</td><td>-1</td><td>&quot; conc-end-of-file-token&quot;</td><td>false</td><td>false</td></tr><tr><td>100</td><td>27276</td><td>27276</td><td>0</td><td>&quot;\n",
       "\n",
       "\t&quot;</td><td>false</td><td>true</td></tr><tr><td>101</td><td>15682</td><td>22848</td><td>0</td><td>&quot;The&quot;</td><td>false</td><td>false</td></tr><tr><td>102</td><td>4361</td><td>41672</td><td>0</td><td>&quot;Fulton&quot;</td><td>false</td><td>false</td></tr><tr><td>103</td><td>14610</td><td>29725</td><td>0</td><td>&quot;County&quot;</td><td>false</td><td>false</td></tr><tr><td>104</td><td>54713</td><td>49998</td><td>0</td><td>&quot;Grand&quot;</td><td>false</td><td>false</td></tr><tr><td>105</td><td>45742</td><td>19078</td><td>0</td><td>&quot;Jury&quot;</td><td>false</td><td>false</td></tr><tr><td>106</td><td>53250</td><td>53250</td><td>0</td><td>&quot;said&quot;</td><td>false</td><td>false</td></tr><tr><td>107</td><td>8699</td><td>35796</td><td>0</td><td>&quot;Friday&quot;</td><td>false</td><td>false</td></tr><tr><td>108</td><td>45680</td><td>45680</td><td>0</td><td>&quot;an&quot;</td><td>false</td><td>false</td></tr><tr><td>109</td><td>30305</td><td>30305</td><td>0</td><td>&quot;investigation&quot;</td><td>false</td><td>false</td></tr><tr><td>110</td><td>2739</td><td>2739</td><td>0</td><td>&quot;of&quot;</td><td>false</td><td>false</td></tr><tr><td>111</td><td>38486</td><td>35571</td><td>0</td><td>&quot;Atlanta&quot;</td><td>false</td><td>false</td></tr><tr><td>112</td><td>49732</td><td>49732</td><td>0</td><td>&quot;&#x27;s&quot;</td><td>false</td><td>false</td></tr><tr><td>113</td><td>42720</td><td>42720</td><td>0</td><td>&quot;recent&quot;</td><td>false</td><td>false</td></tr><tr><td>114</td><td>12294</td><td>12294</td><td>0</td><td>&quot;primary&quot;</td><td>false</td><td>false</td></tr><tr><td>115</td><td>29461</td><td>29461</td><td>0</td><td>&quot;election&quot;</td><td>false</td><td>false</td></tr><tr><td>116</td><td>42473</td><td>42473</td><td>0</td><td>&quot;produced&quot;</td><td>false</td><td>false</td></tr><tr><td>117</td><td>1601</td><td>1601</td><td>0</td><td>&quot;`&quot;</td><td>true</td><td>false</td></tr><tr><td>118</td><td>1601</td><td>1601</td><td>0</td><td>&quot;`&quot;</td><td>true</td><td>false</td></tr><tr><td>119</td><td>39507</td><td>39507</td><td>0</td><td>&quot;no&quot;</td><td>false</td><td>false</td></tr><tr><td>120</td><td>9335</td><td>9335</td><td>0</td><td>&quot;evidence&quot;</td><td>false</td><td>false</td></tr><tr><td>121</td><td>42833</td><td>42833</td><td>0</td><td>&quot;&#x27;&#x27;&quot;</td><td>true</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────────┬────────────┬─────────────┬─────────────────┬─────────────────────────┬──────────┬──────────┐\n",
       "│ position ┆ orth_index ┆ lower_index ┆ token2doc_index ┆ token                   ┆ is_punct ┆ is_space │\n",
       "╞══════════╪════════════╪═════════════╪═════════════════╪═════════════════════════╪══════════╪══════════╡\n",
       "│ 99       ┆ 46333      ┆ 46333       ┆ -1              ┆  conc-end-of-file-token ┆ false    ┆ false    │\n",
       "│ 100      ┆ 27276      ┆ 27276       ┆ 0               ┆                         ┆ false    ┆ true     │\n",
       "│          ┆            ┆             ┆                 ┆                         ┆          ┆          │\n",
       "│          ┆            ┆             ┆                 ┆ \t                       ┆          ┆          │\n",
       "│ 101      ┆ 15682      ┆ 22848       ┆ 0               ┆ The                     ┆ false    ┆ false    │\n",
       "│ 102      ┆ 4361       ┆ 41672       ┆ 0               ┆ Fulton                  ┆ false    ┆ false    │\n",
       "│ 103      ┆ 14610      ┆ 29725       ┆ 0               ┆ County                  ┆ false    ┆ false    │\n",
       "│ 104      ┆ 54713      ┆ 49998       ┆ 0               ┆ Grand                   ┆ false    ┆ false    │\n",
       "│ 105      ┆ 45742      ┆ 19078       ┆ 0               ┆ Jury                    ┆ false    ┆ false    │\n",
       "│ 106      ┆ 53250      ┆ 53250       ┆ 0               ┆ said                    ┆ false    ┆ false    │\n",
       "│ 107      ┆ 8699       ┆ 35796       ┆ 0               ┆ Friday                  ┆ false    ┆ false    │\n",
       "│ 108      ┆ 45680      ┆ 45680       ┆ 0               ┆ an                      ┆ false    ┆ false    │\n",
       "│ 109      ┆ 30305      ┆ 30305       ┆ 0               ┆ investigation           ┆ false    ┆ false    │\n",
       "│ 110      ┆ 2739       ┆ 2739        ┆ 0               ┆ of                      ┆ false    ┆ false    │\n",
       "│ 111      ┆ 38486      ┆ 35571       ┆ 0               ┆ Atlanta                 ┆ false    ┆ false    │\n",
       "│ 112      ┆ 49732      ┆ 49732       ┆ 0               ┆ 's                      ┆ false    ┆ false    │\n",
       "│ 113      ┆ 42720      ┆ 42720       ┆ 0               ┆ recent                  ┆ false    ┆ false    │\n",
       "│ 114      ┆ 12294      ┆ 12294       ┆ 0               ┆ primary                 ┆ false    ┆ false    │\n",
       "│ 115      ┆ 29461      ┆ 29461       ┆ 0               ┆ election                ┆ false    ┆ false    │\n",
       "│ 116      ┆ 42473      ┆ 42473       ┆ 0               ┆ produced                ┆ false    ┆ false    │\n",
       "│ 117      ┆ 1601       ┆ 1601        ┆ 0               ┆ `                       ┆ true     ┆ false    │\n",
       "│ 118      ┆ 1601       ┆ 1601        ┆ 0               ┆ `                       ┆ true     ┆ false    │\n",
       "│ 119      ┆ 39507      ┆ 39507       ┆ 0               ┆ no                      ┆ false    ┆ false    │\n",
       "│ 120      ┆ 9335       ┆ 9335        ┆ 0               ┆ evidence                ┆ false    ┆ false    │\n",
       "│ 121      ┆ 42833      ┆ 42833       ┆ 0               ┆ ''                      ┆ true     ┆ false    │\n",
       "└──────────┴────────────┴─────────────┴─────────────────┴─────────────────────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: true\n",
    "pl.scan_parquet(f'{brown.corpus_path}/tokens.parquet').with_row_index('position').filter(pl.col('position').is_between(99, 121)).join(\n",
    "    pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').select(pl.col('token_id'), pl.col('token'), pl.col('is_punct'), pl.col('is_space')),\n",
    "    left_on='orth_index', right_on='token_id', how='left', maintain_order='left').collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f451875",
   "metadata": {},
   "source": [
    "### spaces.parquet and puncts.parquet\n",
    "\n",
    "The format of spaces.parquet and puncts.parquet are the same. Each table contains one field, namely `position`, which indexes the position of punctuation or space tokens in the corpus. Here are the first three rows of a `puncts.parquet` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d22e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>position</th></tr></thead><tbody><tr><td>117</td></tr><tr><td>118</td></tr><tr><td>121</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────────┐\n",
       "│ position │\n",
       "╞══════════╡\n",
       "│ 117      │\n",
       "│ 118      │\n",
       "│ 121      │\n",
       "└──────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: true\n",
    "pl.scan_parquet(f'{brown.corpus_path}/puncts.parquet').head(3).collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fcfc1",
   "metadata": {},
   "source": [
    "### metadata.parquet\n",
    "\n",
    "The `metadata.parquet` should not be confused with the metadata of the corpus itself, which is accessible in `corpus.jon`.\n",
    "\n",
    "If populated, the `metadata.parquet` file contains metadata for each document in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7aa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>speech_id</th><th>date</th><th>speaker</th><th>chamber</th><th>state</th></tr></thead><tbody><tr><td>530182158</td><td>&quot;1895-01-10T00:00:00.000000&quot;</td><td>&quot;Mr. COCKRELL&quot;</td><td>&quot;S&quot;</td><td>&quot;Unknown&quot;</td></tr><tr><td>890274849</td><td>&quot;1966-08-31T00:00:00.000000&quot;</td><td>&quot;Mr. LONG of Louisiana&quot;</td><td>&quot;S&quot;</td><td>&quot;Louisiana&quot;</td></tr><tr><td>880088363</td><td>&quot;1963-09-11T00:00:00.000000&quot;</td><td>&quot;Mr. FULBRIGHT&quot;</td><td>&quot;S&quot;</td><td>&quot;Unknown&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌───────────┬────────────────────────────┬───────────────────────┬─────────┬───────────┐\n",
       "│ speech_id ┆ date                       ┆ speaker               ┆ chamber ┆ state     │\n",
       "╞═══════════╪════════════════════════════╪═══════════════════════╪═════════╪═══════════╡\n",
       "│ 530182158 ┆ 1895-01-10T00:00:00.000000 ┆ Mr. COCKRELL          ┆ S       ┆ Unknown   │\n",
       "│ 890274849 ┆ 1966-08-31T00:00:00.000000 ┆ Mr. LONG of Louisiana ┆ S       ┆ Louisiana │\n",
       "│ 880088363 ┆ 1963-09-11T00:00:00.000000 ┆ Mr. FULBRIGHT         ┆ S       ┆ Unknown   │\n",
       "└───────────┴────────────────────────────┴───────────────────────┴─────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: true\n",
    "corpus = Corpus().load(f'{save_path}/us-congressional-speeches-subset-10k.corpus')\n",
    "display(pl.scan_parquet(f'{corpus.corpus_path}/metadata.parquet').head(3).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f054f81",
   "metadata": {},
   "source": [
    "For corpora created from files, there will always be a field for the source file at the time of creation. This is in the same order as documents are represented in the `tokens.parquet` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0fb134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>file</th></tr></thead><tbody><tr><td>&quot;an-ideal-family.txt&quot;</td></tr><tr><td>&quot;at-the-bay.txt&quot;</td></tr><tr><td>&quot;bank-holiday.txt&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌─────────────────────┐\n",
       "│ file                │\n",
       "╞═════════════════════╡\n",
       "│ an-ideal-family.txt │\n",
       "│ at-the-bay.txt      │\n",
       "│ bank-holiday.txt    │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: true\n",
    "corpus = Corpus().load(f'{save_path}/garden-party.corpus')\n",
    "display(pl.scan_parquet(f'{corpus.corpus_path}/metadata.parquet').head(3).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfafa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
