{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6713975",
   "metadata": {},
   "source": [
    "# Anatomy of a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048f2c2",
   "metadata": {},
   "source": [
    "This page is intended to provide information on the Conc corpus format in case you want to work with the data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63cdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import polars as pl\n",
    "import os\n",
    "import msgspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "source_path = f'{os.environ.get(\"HOME\")}/data/'\n",
    "save_path = f'{os.environ.get(\"HOME\")}/data/conc-test-corpora/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad510588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from conc.corpus import Corpus, CorpusMetadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3a11e",
   "metadata": {},
   "source": [
    "A Conc corpus is a directory containing specific files as follows:\n",
    "\n",
    "```\n",
    "corpus-name.corpus/\n",
    "\tREADME.md - Human readable information about the corpus to aide distribution\n",
    "\tcorpus.json - Machine readable information about the corpus, including name, description, various summary statistics, and models used to build the corpus\n",
    "\tvocab.parquet - A table mapping token strings to token IDs and frequency information\n",
    "\ttokens.parquet - A table with indices based on token positions used to query the corpus with tokens represented by numeric IDs\n",
    "\tmetadata.parquet - A table with metadata for each document (if there is any)\n",
    "\tspaces.parquet = A table to allow recovery of document spacing without the original texts\n",
    "\tpunct.parquet - A table with punctuation positions\n",
    "```\n",
    "\n",
    "Note: by default the library creates a directory with the `.corpus` suffix. This is done automatically on build, but the directory can be renamed and still loaded. The .corpus extension is intended to make corpora on your filesystem easier to find or identify.\n",
    "\n",
    "To distribute a corpus, send a zip of the directory for others to extract or just share the directory as-is. \n",
    "\n",
    "Below is more information about each file. You can obviously work with a corpus using Conc, but you can work with the processed corpus `.parquet` files directly using the `polars` library. The following information should help you with this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219163c",
   "metadata": {},
   "source": [
    "### README.md\n",
    "\n",
    "Below is an example of the README.md file generated by the Conc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24402bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96baf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "source_path = f'{os.environ.get(\"HOME\")}/data/'\n",
    "save_path = f'{os.environ.get(\"HOME\")}/data/conc-test-corpora/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "brown = Corpus().load(f'{save_path}/brown.corpus')\n",
    "toy = Corpus().load(f'{save_path}/toy.corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4f1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"alert alert-block alert-success\">\n",
       "\n",
       "## Brown Corpus\n",
       "\n",
       "### About\n",
       "\n",
       "This directory contains a corpus created using the [Conc](https://github.com/polsci/conc) Python library. \n",
       "\n",
       "### Corpus Information\n",
       "\n",
       "A Standard Corpus of Present-Day Edited American English, for use with Digital Computers. by W. N. Francis and H. Kucera (1964) Department of Linguistics, Brown University Providence, Rhode Island, USA Revised 1971, Revised and Amplified 1979 http://www.hit.uib.no/icame/brown/bcm.html. This version downloaded via NLTK https://www.nltk.org/nltk_data/.\n",
       "\n",
       "Date created: 2025-06-09 15:46:25  \n",
       "Document count: 500  \n",
       "Token count: 1138566  \n",
       "Word token count: 980144  \n",
       "Unique tokens: 42930  \n",
       "Unique word tokens: 42907  \n",
       "Conc Version Number: 0.0.1  \n",
       "spaCy model: en_core_web_sm, version 3.8.0  \n",
       "\n",
       "### Using this corpus\n",
       "\n",
       "Conc can be installed [via pip]():  \n",
       "```\n",
       "pip install conc\n",
       "```\n",
       "Documentation to get you started with Conc are available:\n",
       "[Conc Documentation](https://geoffford.nz/conc)\n",
       "\n",
       "### Cite Conc\n",
       "\n",
       "If you use Conc in your work, please cite it as follows:\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "with open(f'{brown.corpus_path}/README.md', 'rb') as f:\n",
    "    markdown = '<div class=\"alert alert-block alert-success\">\\n\\n' + f.read().decode('utf-8') + '\\n'\n",
    "    markdown = markdown.replace('\\n#', '\\n##') # making headings smaller for display\n",
    "    markdown += '</div>'\n",
    "    display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee41ffa",
   "metadata": {},
   "source": [
    "### corpus.json file\n",
    "\n",
    "Below is the schema of the `corpus.json` file showing metadata saved with a corpus. These are loaded by Conc as attributes using `Corpus.load` or are created when you build a corpus using `Corpus.build_from_files` or `Corpus.build_from_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bcca47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': {'type': 'string'},\n",
       " 'description': {'type': 'string'},\n",
       " 'slug': {'type': 'string'},\n",
       " 'conc_version': {'type': 'string'},\n",
       " 'document_count': {'type': 'integer'},\n",
       " 'token_count': {'type': 'integer'},\n",
       " 'word_token_count': {'type': 'integer'},\n",
       " 'punct_token_count': {'type': 'integer'},\n",
       " 'space_token_count': {'type': 'integer'},\n",
       " 'unique_tokens': {'type': 'integer'},\n",
       " 'unique_word_tokens': {'type': 'integer'},\n",
       " 'date_created': {'type': 'string'},\n",
       " 'EOF_TOKEN': {'type': 'integer'},\n",
       " 'SPACY_EOF_TOKEN': {'type': 'integer'},\n",
       " 'SPACY_MODEL': {'type': 'string'},\n",
       " 'SPACY_MODEL_VERSION': {'type': 'string'},\n",
       " 'punct_tokens': {'type': 'array', 'items': {'type': 'integer'}},\n",
       " 'space_tokens': {'type': 'array', 'items': {'type': 'integer'}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "properties = msgspec.json.schema(CorpusMetadata)['$defs']['CorpusMetadata']['properties']\n",
    "display(properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac9e2a",
   "metadata": {},
   "source": [
    "Some of this information is exposed by `Corpus` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de59ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"gzzhvxhtho\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n",
       "<style>\n",
       "#gzzhvxhtho table {\n",
       "          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n",
       "          -webkit-font-smoothing: antialiased;\n",
       "          -moz-osx-font-smoothing: grayscale;\n",
       "        }\n",
       "\n",
       "#gzzhvxhtho thead, tbody, tfoot, tr, td, th { border-style: none; }\n",
       " tr { background-color: transparent; }\n",
       "#gzzhvxhtho p { margin: 0; padding: 0; }\n",
       " #gzzhvxhtho .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: 0; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n",
       " #gzzhvxhtho .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n",
       " #gzzhvxhtho .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n",
       " #gzzhvxhtho .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n",
       " #gzzhvxhtho .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n",
       " #gzzhvxhtho .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n",
       " #gzzhvxhtho .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n",
       " #gzzhvxhtho .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n",
       " #gzzhvxhtho .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n",
       " #gzzhvxhtho .gt_column_spanner_outer:first-child { padding-left: 0; }\n",
       " #gzzhvxhtho .gt_column_spanner_outer:last-child { padding-right: 0; }\n",
       " #gzzhvxhtho .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n",
       " #gzzhvxhtho .gt_spanner_row { border-bottom-style: hidden; }\n",
       " #gzzhvxhtho .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n",
       " #gzzhvxhtho .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n",
       " #gzzhvxhtho .gt_from_md> :first-child { margin-top: 0; }\n",
       " #gzzhvxhtho .gt_from_md> :last-child { margin-bottom: 0; }\n",
       " #gzzhvxhtho .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n",
       " #gzzhvxhtho .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n",
       " #gzzhvxhtho .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n",
       " #gzzhvxhtho .gt_row_group_first td { border-top-width: 2px; }\n",
       " #gzzhvxhtho .gt_row_group_first th { border-top-width: 2px; }\n",
       " #gzzhvxhtho .gt_striped { background-color: rgba(128,128,128,0.05); }\n",
       " #gzzhvxhtho .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n",
       " #gzzhvxhtho .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n",
       " #gzzhvxhtho .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n",
       " #gzzhvxhtho .gt_left { text-align: left; }\n",
       " #gzzhvxhtho .gt_center { text-align: center; }\n",
       " #gzzhvxhtho .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n",
       " #gzzhvxhtho .gt_font_normal { font-weight: normal; }\n",
       " #gzzhvxhtho .gt_font_bold { font-weight: bold; }\n",
       " #gzzhvxhtho .gt_font_italic { font-style: italic; }\n",
       " #gzzhvxhtho .gt_super { font-size: 65%; }\n",
       " #gzzhvxhtho .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n",
       " #gzzhvxhtho .gt_asterisk { font-size: 100%; vertical-align: 0; }\n",
       " \n",
       "</style>\n",
       "<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n",
       "<thead>\n",
       "\n",
       "  <tr class=\"gt_heading\">\n",
       "    <td colspan=\"2\" class=\"gt_heading gt_title gt_font_normal\">Corpus Summary</td>\n",
       "  </tr>\n",
       "  <tr class=\"gt_heading\">\n",
       "    <td colspan=\"2\" class=\"gt_heading gt_subtitle gt_font_normal gt_bottom_border\"></td>\n",
       "  </tr>\n",
       "<tr class=\"gt_col_headings\">\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Attribute\">Attribute</th>\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Value\">Value</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody class=\"gt_table_body\">\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Name</td>\n",
       "    <td class=\"gt_row gt_left\">Brown Corpus</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Description</td>\n",
       "    <td class=\"gt_row gt_left\">A Standard Corpus of Present-Day Edited American English, for use with Digital Computers. by W. N. Francis and H. Kucera (1964) Department of Linguistics, Brown University Providence, Rhode Island, USA Revised 1971, Revised and Amplified 1979 http://www.hit.uib.no/icame/brown/bcm.html. This version downloaded via NLTK https://www.nltk.org/nltk_data/.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Date Created</td>\n",
       "    <td class=\"gt_row gt_left\">2025-06-09 15:46:25</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Conc Version</td>\n",
       "    <td class=\"gt_row gt_left\">0.0.1</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Corpus Path</td>\n",
       "    <td class=\"gt_row gt_left\">/home/geoff/data/conc-test-corpora//brown.corpus</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Document Count</td>\n",
       "    <td class=\"gt_row gt_left\">500</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Token Count</td>\n",
       "    <td class=\"gt_row gt_left\">1,138,566</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Word Token Count</td>\n",
       "    <td class=\"gt_row gt_left\">980,144</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Unique Tokens</td>\n",
       "    <td class=\"gt_row gt_left\">42,930</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">Unique Word Tokens</td>\n",
       "    <td class=\"gt_row gt_left\">42,907</td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "\n",
       "\n",
       "</table>\n",
       "\n",
       "</div>\n",
       "        "
      ]
     },
     "metadata": {
      "text/html": {
       "text/html": {
        "isolated": true
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "brown.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c199320",
   "metadata": {},
   "source": [
    "### vocab.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6df38",
   "metadata": {},
   "source": [
    "The vocab table contains ...\n",
    "\n",
    "1. A lookup between token_id, token (string representation), and tokens_sort_order. The sort order allows sorting tokens alphabetically directly from token ids.\n",
    "2. A frequency table, with counts for lower case and case sensitive matching.\n",
    "3. Information on the type of token (i.e. whether punctuation or space - or if neither of those, a \"word\" token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb32cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>rank</th><th>tokens_sort_order</th><th>token_id</th><th>token</th><th>frequency_lower</th><th>frequency_orth</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>1</td><td>50087</td><td>22848</td><td>&quot;the&quot;</td><td>63516</td><td>62473</td><td>false</td><td>false</td></tr><tr><td>2</td><td>28</td><td>8128</td><td>&quot;,&quot;</td><td>58331</td><td>58331</td><td>true</td><td>false</td></tr><tr><td>3</td><td>41</td><td>38309</td><td>&quot;.&quot;</td><td>49907</td><td>49907</td><td>true</td><td>false</td></tr><tr><td>4</td><td>35232</td><td>2739</td><td>&quot;of&quot;</td><td>36321</td><td>36122</td><td>false</td><td>false</td></tr><tr><td>5</td><td>3351</td><td>7126</td><td>&quot;and&quot;</td><td>27787</td><td>27633</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────┬───────────────────┬──────────┬───────┬─────────────────┬────────────────┬──────────┬──────────┐\n",
       "│ rank ┆ tokens_sort_order ┆ token_id ┆ token ┆ frequency_lower ┆ frequency_orth ┆ is_punct ┆ is_space │\n",
       "╞══════╪═══════════════════╪══════════╪═══════╪═════════════════╪════════════════╪══════════╪══════════╡\n",
       "│ 1    ┆ 50087             ┆ 22848    ┆ the   ┆ 63516           ┆ 62473          ┆ false    ┆ false    │\n",
       "│ 2    ┆ 28                ┆ 8128     ┆ ,     ┆ 58331           ┆ 58331          ┆ true     ┆ false    │\n",
       "│ 3    ┆ 41                ┆ 38309    ┆ .     ┆ 49907           ┆ 49907          ┆ true     ┆ false    │\n",
       "│ 4    ┆ 35232             ┆ 2739     ┆ of    ┆ 36321           ┆ 36122          ┆ false    ┆ false    │\n",
       "│ 5    ┆ 3351              ┆ 7126     ┆ and   ┆ 27787           ┆ 27633          ┆ false    ┆ false    │\n",
       "└──────┴───────────────────┴──────────┴───────┴─────────────────┴────────────────┴──────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "display(pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').head(5).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b388d",
   "metadata": {},
   "source": [
    "To illustrate the how frequencies are stored, see the instances for 'the'. The counts for the form as it appeared in the text are stored in frequency_orth. 'The' appears 1043 times and 'the' as lowercase appears 62,473 times. The frequency_lower column provides a count of the total number of mentions of 'the' regardless of case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>rank</th><th>tokens_sort_order</th><th>token_id</th><th>token</th><th>frequency_lower</th><th>frequency_orth</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>1</td><td>50087</td><td>22848</td><td>&quot;the&quot;</td><td>63516</td><td>62473</td><td>false</td><td>false</td></tr><tr><td>99</td><td>50086</td><td>15682</td><td>&quot;The&quot;</td><td>null</td><td>1043</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────┬───────────────────┬──────────┬───────┬─────────────────┬────────────────┬──────────┬──────────┐\n",
       "│ rank ┆ tokens_sort_order ┆ token_id ┆ token ┆ frequency_lower ┆ frequency_orth ┆ is_punct ┆ is_space │\n",
       "╞══════╪═══════════════════╪══════════╪═══════╪═════════════════╪════════════════╪══════════╪══════════╡\n",
       "│ 1    ┆ 50087             ┆ 22848    ┆ the   ┆ 63516           ┆ 62473          ┆ false    ┆ false    │\n",
       "│ 99   ┆ 50086             ┆ 15682    ┆ The   ┆ null            ┆ 1043           ┆ false    ┆ false    │\n",
       "└──────┴───────────────────┴──────────┴───────┴─────────────────┴────────────────┴──────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "display(pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').filter(pl.col('token').str.to_lowercase() == 'the').head(5).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978152b",
   "metadata": {},
   "source": [
    "Punctuation is included in tokens, but these can be filtered in Conc reports. If you are working with the table directly you can use `is_punct` to access or remove punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eacaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>rank</th><th>tokens_sort_order</th><th>token_id</th><th>token</th><th>frequency_lower</th><th>frequency_orth</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>2</td><td>28</td><td>8128</td><td>&quot;,&quot;</td><td>58331</td><td>58331</td><td>true</td><td>false</td></tr><tr><td>3</td><td>41</td><td>38309</td><td>&quot;.&quot;</td><td>49907</td><td>49907</td><td>true</td><td>false</td></tr><tr><td>12</td><td>1577</td><td>1601</td><td>&quot;`&quot;</td><td>9788</td><td>9788</td><td>true</td><td>false</td></tr><tr><td>14</td><td>14</td><td>42833</td><td>&quot;&#x27;&#x27;&quot;</td><td>8762</td><td>8762</td><td>true</td><td>false</td></tr><tr><td>15</td><td>29</td><td>27963</td><td>&quot;-&quot;</td><td>8131</td><td>8131</td><td>true</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────┬───────────────────┬──────────┬───────┬─────────────────┬────────────────┬──────────┬──────────┐\n",
       "│ rank ┆ tokens_sort_order ┆ token_id ┆ token ┆ frequency_lower ┆ frequency_orth ┆ is_punct ┆ is_space │\n",
       "╞══════╪═══════════════════╪══════════╪═══════╪═════════════════╪════════════════╪══════════╪══════════╡\n",
       "│ 2    ┆ 28                ┆ 8128     ┆ ,     ┆ 58331           ┆ 58331          ┆ true     ┆ false    │\n",
       "│ 3    ┆ 41                ┆ 38309    ┆ .     ┆ 49907           ┆ 49907          ┆ true     ┆ false    │\n",
       "│ 12   ┆ 1577              ┆ 1601     ┆ `     ┆ 9788            ┆ 9788           ┆ true     ┆ false    │\n",
       "│ 14   ┆ 14                ┆ 42833    ┆ ''    ┆ 8762            ┆ 8762           ┆ true     ┆ false    │\n",
       "│ 15   ┆ 29                ┆ 27963    ┆ -     ┆ 8131            ┆ 8131           ┆ true     ┆ false    │\n",
       "└──────┴───────────────────┴──────────┴───────┴─────────────────┴────────────────┴──────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "display(pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').filter(pl.col('is_punct') == True).head(5).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b9348",
   "metadata": {},
   "source": [
    "Likewise, space tokens are included (without counts). There is more on space tokens below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3009bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>rank</th><th>tokens_sort_order</th><th>token_id</th><th>token</th><th>frequency_lower</th><th>frequency_orth</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>47165</td><td>1</td><td>2956</td><td>&quot;\n",
       "&quot;</td><td>null</td><td>null</td><td>false</td><td>true</td></tr><tr><td>47166</td><td>2</td><td>2799</td><td>&quot;\n",
       "\n",
       "&quot;</td><td>null</td><td>null</td><td>false</td><td>true</td></tr><tr><td>47167</td><td>3</td><td>27276</td><td>&quot;\n",
       "\n",
       "\t&quot;</td><td>null</td><td>null</td><td>false</td><td>true</td></tr><tr><td>47168</td><td>4</td><td>22812</td><td>&quot;\n",
       "\n",
       "\n",
       "&quot;</td><td>null</td><td>null</td><td>false</td><td>true</td></tr><tr><td>47169</td><td>5</td><td>4112</td><td>&quot;\n",
       "\n",
       "\n",
       "\t&quot;</td><td>null</td><td>null</td><td>false</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌───────┬───────────────────┬──────────┬───────┬─────────────────┬────────────────┬──────────┬──────────┐\n",
       "│ rank  ┆ tokens_sort_order ┆ token_id ┆ token ┆ frequency_lower ┆ frequency_orth ┆ is_punct ┆ is_space │\n",
       "╞═══════╪═══════════════════╪══════════╪═══════╪═════════════════╪════════════════╪══════════╪══════════╡\n",
       "│ 47165 ┆ 1                 ┆ 2956     ┆       ┆ null            ┆ null           ┆ false    ┆ true     │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│ 47166 ┆ 2                 ┆ 2799     ┆       ┆ null            ┆ null           ┆ false    ┆ true     │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│ 47167 ┆ 3                 ┆ 27276    ┆       ┆ null            ┆ null           ┆ false    ┆ true     │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│       ┆                   ┆          ┆ \t     ┆                 ┆                ┆          ┆          │\n",
       "│ 47168 ┆ 4                 ┆ 22812    ┆       ┆ null            ┆ null           ┆ false    ┆ true     │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│ 47169 ┆ 5                 ┆ 4112     ┆       ┆ null            ┆ null           ┆ false    ┆ true     │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│       ┆                   ┆          ┆       ┆                 ┆                ┆          ┆          │\n",
       "│       ┆                   ┆          ┆ \t     ┆                 ┆                ┆          ┆          │\n",
       "└───────┴───────────────────┴──────────┴───────┴─────────────────┴────────────────┴──────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "display(pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').filter(pl.col('is_space') == True).head(5).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776487e",
   "metadata": {},
   "source": [
    "### tokens.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffce4d5",
   "metadata": {},
   "source": [
    "The `tokens.parquet` file contains a table representing tokens in the corpus. Whitespace tokens have been removed (see `spaces.parquet` discussion below). The columns are as follows:\n",
    "\n",
    "- the `orth_index` column stores the token_id of the original form of the token\n",
    "- the `lower_index` column stores the token_id of the lowercased form of the token  \n",
    "- the `token2doc_index` column stores the document id assigned by Conc in the order the texts where processed (starting from index position 1) - this is the same order as the metadata in the `metadata.parquet` file.\n",
    "- the `has_spaces` column stores a boolean value indicating if the token is followed by a standard space character or not.\n",
    "\n",
    "To demarcate the start and end of documents, Conc uses an end of file token (EOF_TOKEN) in the orth_index and lower_index columns. The EOF_TOKEN is stored in `corpus.json` and is accessible as a property of a `Corpus` object.\n",
    "\n",
    "The token2doc_index represents token positions outside texts in the corpus as -1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5145b",
   "metadata": {},
   "source": [
    "#### A note about space tokens\n",
    "\n",
    "SpaCy outputs whether tokens are followed by a standard space character. This is recorded in has_spaces in the tokens table. SpaCy creates space tokens for other whitespace sequences. This may be useful for some sequence classification problems and it is allows re-representation of the document in its original form (i.e. newlines, tabs and sequences of whitespace) preserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cd68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>position</th><th>orth_index</th><th>lower_index</th><th>token2doc_index</th><th>has_spaces</th></tr></thead><tbody><tr><td>99</td><td>46333</td><td>46333</td><td>-1</td><td>false</td></tr><tr><td>100</td><td>15682</td><td>22848</td><td>1</td><td>true</td></tr><tr><td>101</td><td>4361</td><td>41672</td><td>1</td><td>true</td></tr><tr><td>102</td><td>14610</td><td>29725</td><td>1</td><td>true</td></tr><tr><td>103</td><td>54713</td><td>49998</td><td>1</td><td>true</td></tr><tr><td>104</td><td>45742</td><td>19078</td><td>1</td><td>true</td></tr><tr><td>105</td><td>53250</td><td>53250</td><td>1</td><td>true</td></tr><tr><td>106</td><td>8699</td><td>35796</td><td>1</td><td>true</td></tr><tr><td>107</td><td>45680</td><td>45680</td><td>1</td><td>true</td></tr><tr><td>108</td><td>30305</td><td>30305</td><td>1</td><td>true</td></tr><tr><td>109</td><td>2739</td><td>2739</td><td>1</td><td>true</td></tr><tr><td>110</td><td>38486</td><td>35571</td><td>1</td><td>false</td></tr><tr><td>111</td><td>49732</td><td>49732</td><td>1</td><td>true</td></tr><tr><td>112</td><td>42720</td><td>42720</td><td>1</td><td>true</td></tr><tr><td>113</td><td>12294</td><td>12294</td><td>1</td><td>true</td></tr><tr><td>114</td><td>29461</td><td>29461</td><td>1</td><td>true</td></tr><tr><td>115</td><td>42473</td><td>42473</td><td>1</td><td>true</td></tr><tr><td>116</td><td>1601</td><td>1601</td><td>1</td><td>false</td></tr><tr><td>117</td><td>1601</td><td>1601</td><td>1</td><td>true</td></tr><tr><td>118</td><td>39507</td><td>39507</td><td>1</td><td>true</td></tr><tr><td>119</td><td>9335</td><td>9335</td><td>1</td><td>true</td></tr><tr><td>120</td><td>42833</td><td>42833</td><td>1</td><td>true</td></tr><tr><td>121</td><td>13607</td><td>13607</td><td>1</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────────┬────────────┬─────────────┬─────────────────┬────────────┐\n",
       "│ position ┆ orth_index ┆ lower_index ┆ token2doc_index ┆ has_spaces │\n",
       "╞══════════╪════════════╪═════════════╪═════════════════╪════════════╡\n",
       "│ 99       ┆ 46333      ┆ 46333       ┆ -1              ┆ false      │\n",
       "│ 100      ┆ 15682      ┆ 22848       ┆ 1               ┆ true       │\n",
       "│ 101      ┆ 4361       ┆ 41672       ┆ 1               ┆ true       │\n",
       "│ 102      ┆ 14610      ┆ 29725       ┆ 1               ┆ true       │\n",
       "│ 103      ┆ 54713      ┆ 49998       ┆ 1               ┆ true       │\n",
       "│ 104      ┆ 45742      ┆ 19078       ┆ 1               ┆ true       │\n",
       "│ 105      ┆ 53250      ┆ 53250       ┆ 1               ┆ true       │\n",
       "│ 106      ┆ 8699       ┆ 35796       ┆ 1               ┆ true       │\n",
       "│ 107      ┆ 45680      ┆ 45680       ┆ 1               ┆ true       │\n",
       "│ 108      ┆ 30305      ┆ 30305       ┆ 1               ┆ true       │\n",
       "│ 109      ┆ 2739       ┆ 2739        ┆ 1               ┆ true       │\n",
       "│ 110      ┆ 38486      ┆ 35571       ┆ 1               ┆ false      │\n",
       "│ 111      ┆ 49732      ┆ 49732       ┆ 1               ┆ true       │\n",
       "│ 112      ┆ 42720      ┆ 42720       ┆ 1               ┆ true       │\n",
       "│ 113      ┆ 12294      ┆ 12294       ┆ 1               ┆ true       │\n",
       "│ 114      ┆ 29461      ┆ 29461       ┆ 1               ┆ true       │\n",
       "│ 115      ┆ 42473      ┆ 42473       ┆ 1               ┆ true       │\n",
       "│ 116      ┆ 1601       ┆ 1601        ┆ 1               ┆ false      │\n",
       "│ 117      ┆ 1601       ┆ 1601        ┆ 1               ┆ true       │\n",
       "│ 118      ┆ 39507      ┆ 39507       ┆ 1               ┆ true       │\n",
       "│ 119      ┆ 9335       ┆ 9335        ┆ 1               ┆ true       │\n",
       "│ 120      ┆ 42833      ┆ 42833       ┆ 1               ┆ true       │\n",
       "│ 121      ┆ 13607      ┆ 13607       ┆ 1               ┆ true       │\n",
       "└──────────┴────────────┴─────────────┴─────────────────┴────────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pl.scan_parquet(f'{brown.corpus_path}/tokens.parquet').with_row_index('position').filter(pl.col('position').is_between(99, 121)).collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5140a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# tmp_tokens_df = pl.scan_parquet(f'{brown.corpus_path}/tokens.parquet').with_row_index('position').collect()\n",
    "# display(tmp_tokens_df.filter(pl.col('position').is_between(99, 121)).head(5))\n",
    "# display(tmp_tokens_df.filter(pl.col('position').is_between(343, 348)).head(5))\n",
    "\n",
    "# space_tokens_df = tmp_tokens_df.filter((pl.col('orth_index').is_in(brown.space_tokens))).with_row_index('adjust_by').with_columns((pl.col('position') - pl.col('adjust_by')).alias('corrected'))\n",
    "# # replace position with corrected \n",
    "# space_tokens_df = space_tokens_df.with_columns(pl.col('corrected').alias('position')).drop('adjust_by').drop('corrected')\n",
    "# # remove space_tokens_df from tmp_tokens_df\n",
    "# tmp_tokens_df = tmp_tokens_df.filter(~pl.col('orth_index').is_in(brown.space_tokens)).drop('position').with_row_index('position')\n",
    "\n",
    "# tmp_tokens_df = tmp_tokens_df.with_columns(pl.lit(1).alias('not_space'))\n",
    "# space_tokens_df = space_tokens_df.with_columns(pl.lit(0).alias('not_space'))\n",
    "\n",
    "# display(tmp_tokens_df.filter(pl.col('position').is_between(99, 121)).head(5))\n",
    "# display(tmp_tokens_df.filter(pl.col('position').is_between(343, 348)).head(5))\n",
    "\n",
    "# display(space_tokens_df.head(5))\n",
    "\n",
    "# reconstructed_df = pl.concat([tmp_tokens_df, space_tokens_df]).sort('position', 'not_space').drop('position').drop('not_space').with_row_index('position')\n",
    "# display(reconstructed_df.filter(pl.col('position').is_between(99, 121)).head(5))\n",
    "# display(reconstructed_df.filter(pl.col('position').is_between(343, 348)).head(5))\n",
    "\n",
    "# # is resconstructed identical to original? programmatically check\n",
    "# assert pl.scan_parquet(f'{brown.corpus_path}/tokens.parquet').collect(engine='streaming').with_row_index('position').equals(reconstructed_df)\n",
    "\n",
    "# # test for just one doc ...\n",
    "# doc_id = 300\n",
    "# tmp_doc_df = tmp_tokens_df.filter(pl.col('token2doc_index') == doc_id)\n",
    "# display(tmp_doc_df.head(5))\n",
    "# reconstructed_df = pl.concat([tmp_doc_df, space_tokens_df.filter(pl.col('token2doc_index') == doc_id)]).sort('position', 'not_space').drop('position').drop('not_space')\n",
    "# display(reconstructed_df.head(5))\n",
    "# assert pl.scan_parquet(f'{brown.corpus_path}/tokens.parquet').filter(pl.col('token2doc_index') == doc_id).collect(engine='streaming').equals(reconstructed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb1b1a",
   "metadata": {},
   "source": [
    "The view below shows tokens joined with vocab, so you can see the token string and the attributes of the tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d4576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>position</th><th>orth_index</th><th>lower_index</th><th>token2doc_index</th><th>has_spaces</th><th>token</th><th>is_punct</th><th>is_space</th></tr></thead><tbody><tr><td>99</td><td>46333</td><td>46333</td><td>-1</td><td>false</td><td>&quot; conc-end-of-file-token&quot;</td><td>false</td><td>false</td></tr><tr><td>100</td><td>15682</td><td>22848</td><td>1</td><td>true</td><td>&quot;The&quot;</td><td>false</td><td>false</td></tr><tr><td>101</td><td>4361</td><td>41672</td><td>1</td><td>true</td><td>&quot;Fulton&quot;</td><td>false</td><td>false</td></tr><tr><td>102</td><td>14610</td><td>29725</td><td>1</td><td>true</td><td>&quot;County&quot;</td><td>false</td><td>false</td></tr><tr><td>103</td><td>54713</td><td>49998</td><td>1</td><td>true</td><td>&quot;Grand&quot;</td><td>false</td><td>false</td></tr><tr><td>104</td><td>45742</td><td>19078</td><td>1</td><td>true</td><td>&quot;Jury&quot;</td><td>false</td><td>false</td></tr><tr><td>105</td><td>53250</td><td>53250</td><td>1</td><td>true</td><td>&quot;said&quot;</td><td>false</td><td>false</td></tr><tr><td>106</td><td>8699</td><td>35796</td><td>1</td><td>true</td><td>&quot;Friday&quot;</td><td>false</td><td>false</td></tr><tr><td>107</td><td>45680</td><td>45680</td><td>1</td><td>true</td><td>&quot;an&quot;</td><td>false</td><td>false</td></tr><tr><td>108</td><td>30305</td><td>30305</td><td>1</td><td>true</td><td>&quot;investigation&quot;</td><td>false</td><td>false</td></tr><tr><td>109</td><td>2739</td><td>2739</td><td>1</td><td>true</td><td>&quot;of&quot;</td><td>false</td><td>false</td></tr><tr><td>110</td><td>38486</td><td>35571</td><td>1</td><td>false</td><td>&quot;Atlanta&quot;</td><td>false</td><td>false</td></tr><tr><td>111</td><td>49732</td><td>49732</td><td>1</td><td>true</td><td>&quot;&#x27;s&quot;</td><td>false</td><td>false</td></tr><tr><td>112</td><td>42720</td><td>42720</td><td>1</td><td>true</td><td>&quot;recent&quot;</td><td>false</td><td>false</td></tr><tr><td>113</td><td>12294</td><td>12294</td><td>1</td><td>true</td><td>&quot;primary&quot;</td><td>false</td><td>false</td></tr><tr><td>114</td><td>29461</td><td>29461</td><td>1</td><td>true</td><td>&quot;election&quot;</td><td>false</td><td>false</td></tr><tr><td>115</td><td>42473</td><td>42473</td><td>1</td><td>true</td><td>&quot;produced&quot;</td><td>false</td><td>false</td></tr><tr><td>116</td><td>1601</td><td>1601</td><td>1</td><td>false</td><td>&quot;`&quot;</td><td>true</td><td>false</td></tr><tr><td>117</td><td>1601</td><td>1601</td><td>1</td><td>true</td><td>&quot;`&quot;</td><td>true</td><td>false</td></tr><tr><td>118</td><td>39507</td><td>39507</td><td>1</td><td>true</td><td>&quot;no&quot;</td><td>false</td><td>false</td></tr><tr><td>119</td><td>9335</td><td>9335</td><td>1</td><td>true</td><td>&quot;evidence&quot;</td><td>false</td><td>false</td></tr><tr><td>120</td><td>42833</td><td>42833</td><td>1</td><td>true</td><td>&quot;&#x27;&#x27;&quot;</td><td>true</td><td>false</td></tr><tr><td>121</td><td>13607</td><td>13607</td><td>1</td><td>true</td><td>&quot;that&quot;</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────────┬────────────┬─────────────┬─────────────────┬────────────┬─────────────────────────┬──────────┬──────────┐\n",
       "│ position ┆ orth_index ┆ lower_index ┆ token2doc_index ┆ has_spaces ┆ token                   ┆ is_punct ┆ is_space │\n",
       "╞══════════╪════════════╪═════════════╪═════════════════╪════════════╪═════════════════════════╪══════════╪══════════╡\n",
       "│ 99       ┆ 46333      ┆ 46333       ┆ -1              ┆ false      ┆  conc-end-of-file-token ┆ false    ┆ false    │\n",
       "│ 100      ┆ 15682      ┆ 22848       ┆ 1               ┆ true       ┆ The                     ┆ false    ┆ false    │\n",
       "│ 101      ┆ 4361       ┆ 41672       ┆ 1               ┆ true       ┆ Fulton                  ┆ false    ┆ false    │\n",
       "│ 102      ┆ 14610      ┆ 29725       ┆ 1               ┆ true       ┆ County                  ┆ false    ┆ false    │\n",
       "│ 103      ┆ 54713      ┆ 49998       ┆ 1               ┆ true       ┆ Grand                   ┆ false    ┆ false    │\n",
       "│ 104      ┆ 45742      ┆ 19078       ┆ 1               ┆ true       ┆ Jury                    ┆ false    ┆ false    │\n",
       "│ 105      ┆ 53250      ┆ 53250       ┆ 1               ┆ true       ┆ said                    ┆ false    ┆ false    │\n",
       "│ 106      ┆ 8699       ┆ 35796       ┆ 1               ┆ true       ┆ Friday                  ┆ false    ┆ false    │\n",
       "│ 107      ┆ 45680      ┆ 45680       ┆ 1               ┆ true       ┆ an                      ┆ false    ┆ false    │\n",
       "│ 108      ┆ 30305      ┆ 30305       ┆ 1               ┆ true       ┆ investigation           ┆ false    ┆ false    │\n",
       "│ 109      ┆ 2739       ┆ 2739        ┆ 1               ┆ true       ┆ of                      ┆ false    ┆ false    │\n",
       "│ 110      ┆ 38486      ┆ 35571       ┆ 1               ┆ false      ┆ Atlanta                 ┆ false    ┆ false    │\n",
       "│ 111      ┆ 49732      ┆ 49732       ┆ 1               ┆ true       ┆ 's                      ┆ false    ┆ false    │\n",
       "│ 112      ┆ 42720      ┆ 42720       ┆ 1               ┆ true       ┆ recent                  ┆ false    ┆ false    │\n",
       "│ 113      ┆ 12294      ┆ 12294       ┆ 1               ┆ true       ┆ primary                 ┆ false    ┆ false    │\n",
       "│ 114      ┆ 29461      ┆ 29461       ┆ 1               ┆ true       ┆ election                ┆ false    ┆ false    │\n",
       "│ 115      ┆ 42473      ┆ 42473       ┆ 1               ┆ true       ┆ produced                ┆ false    ┆ false    │\n",
       "│ 116      ┆ 1601       ┆ 1601        ┆ 1               ┆ false      ┆ `                       ┆ true     ┆ false    │\n",
       "│ 117      ┆ 1601       ┆ 1601        ┆ 1               ┆ true       ┆ `                       ┆ true     ┆ false    │\n",
       "│ 118      ┆ 39507      ┆ 39507       ┆ 1               ┆ true       ┆ no                      ┆ false    ┆ false    │\n",
       "│ 119      ┆ 9335       ┆ 9335        ┆ 1               ┆ true       ┆ evidence                ┆ false    ┆ false    │\n",
       "│ 120      ┆ 42833      ┆ 42833       ┆ 1               ┆ true       ┆ ''                      ┆ true     ┆ false    │\n",
       "│ 121      ┆ 13607      ┆ 13607       ┆ 1               ┆ true       ┆ that                    ┆ false    ┆ false    │\n",
       "└──────────┴────────────┴─────────────┴─────────────────┴────────────┴─────────────────────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pl.scan_parquet(f'{brown.corpus_path}/tokens.parquet').with_row_index('position').filter(pl.col('position').is_between(99, 121)).join(\n",
    "    pl.scan_parquet(f'{brown.corpus_path}/vocab.parquet').select(pl.col('token_id'), pl.col('token'), pl.col('is_punct'), pl.col('is_space')),\n",
    "    left_on='orth_index', right_on='token_id', how='left', maintain_order='left').collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f451875",
   "metadata": {},
   "source": [
    "### spaces.parquet\n",
    "\n",
    "Space tokens (see note above) are stored in `spaces.parquet`. Space tokens are stored separate from word and punctuation tokens. This allows consistency with most tools for corpus linguistics. The spaces table follows the format of the tokens table. Spaces are represented using `position` and the corresponding token_id of the whitespace. The original token sequences can be reconstructed from the `tokens.parquet` and `spaces.parquet` files. Conc has functionality to recover specific texts by recombining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d22e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>position</th><th>orth_index</th><th>lower_index</th><th>token2doc_index</th><th>has_spaces</th></tr></thead><tbody><tr><td>100</td><td>27276</td><td>27276</td><td>1</td><td>false</td></tr><tr><td>345</td><td>2956</td><td>2956</td><td>1</td><td>false</td></tr><tr><td>637</td><td>2956</td><td>2956</td><td>1</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────────┬────────────┬─────────────┬─────────────────┬────────────┐\n",
       "│ position ┆ orth_index ┆ lower_index ┆ token2doc_index ┆ has_spaces │\n",
       "╞══════════╪════════════╪═════════════╪═════════════════╪════════════╡\n",
       "│ 100      ┆ 27276      ┆ 27276       ┆ 1               ┆ false      │\n",
       "│ 345      ┆ 2956       ┆ 2956        ┆ 1               ┆ false      │\n",
       "│ 637      ┆ 2956       ┆ 2956        ┆ 1               ┆ false      │\n",
       "└──────────┴────────────┴─────────────┴─────────────────┴────────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pl.scan_parquet(f'{brown.corpus_path}/spaces.parquet').head(3).collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644b340",
   "metadata": {},
   "source": [
    "### puncts.parquet\n",
    "\n",
    "The `puncts.parquet` file stores an index of the position of punctuation tokens in the corpus. Below are the first three rows of a `puncts.parquet` file. If you look above the positions align with punctuation tokens in the tokens.parquet file. These are intended to be used for filtering tokens to exclude punctuation where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9cfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>position</th></tr></thead><tbody><tr><td>116</td></tr><tr><td>117</td></tr><tr><td>120</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌──────────┐\n",
       "│ position │\n",
       "╞══════════╡\n",
       "│ 116      │\n",
       "│ 117      │\n",
       "│ 120      │\n",
       "└──────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pl.scan_parquet(f'{brown.corpus_path}/puncts.parquet').head(3).collect(engine='streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fcfc1",
   "metadata": {},
   "source": [
    "### metadata.parquet\n",
    "\n",
    "The `metadata.parquet` should not be confused with the metadata of the corpus itself, which is accessible in `corpus.jon`.\n",
    "\n",
    "If populated, the `metadata.parquet` file contains metadata for each document in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7aa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>speech_id</th><th>date</th><th>speaker</th><th>chamber</th><th>state</th></tr></thead><tbody><tr><td>530182158</td><td>&quot;1895-01-10T00:00:00.000000&quot;</td><td>&quot;Mr. COCKRELL&quot;</td><td>&quot;S&quot;</td><td>&quot;Unknown&quot;</td></tr><tr><td>890274849</td><td>&quot;1966-08-31T00:00:00.000000&quot;</td><td>&quot;Mr. LONG of Louisiana&quot;</td><td>&quot;S&quot;</td><td>&quot;Louisiana&quot;</td></tr><tr><td>880088363</td><td>&quot;1963-09-11T00:00:00.000000&quot;</td><td>&quot;Mr. FULBRIGHT&quot;</td><td>&quot;S&quot;</td><td>&quot;Unknown&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌───────────┬────────────────────────────┬───────────────────────┬─────────┬───────────┐\n",
       "│ speech_id ┆ date                       ┆ speaker               ┆ chamber ┆ state     │\n",
       "╞═══════════╪════════════════════════════╪═══════════════════════╪═════════╪═══════════╡\n",
       "│ 530182158 ┆ 1895-01-10T00:00:00.000000 ┆ Mr. COCKRELL          ┆ S       ┆ Unknown   │\n",
       "│ 890274849 ┆ 1966-08-31T00:00:00.000000 ┆ Mr. LONG of Louisiana ┆ S       ┆ Louisiana │\n",
       "│ 880088363 ┆ 1963-09-11T00:00:00.000000 ┆ Mr. FULBRIGHT         ┆ S       ┆ Unknown   │\n",
       "└───────────┴────────────────────────────┴───────────────────────┴─────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "corpus = Corpus().load(f'{save_path}/us-congressional-speeches-subset-10k.corpus')\n",
    "display(pl.scan_parquet(f'{corpus.corpus_path}/metadata.parquet').head(3).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f054f81",
   "metadata": {},
   "source": [
    "Metadata is represented in the same order as documents are stored in the `tokens.parquet` file. The tokens with token2doc_index 1 correspond to the first metadata row.\n",
    "\n",
    "For corpora created from files, there will always be a field for the source file at the time of creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0fb134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>file</th></tr></thead><tbody><tr><td>&quot;an-ideal-family.txt&quot;</td></tr><tr><td>&quot;at-the-bay.txt&quot;</td></tr><tr><td>&quot;bank-holiday.txt&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌─────────────────────┐\n",
       "│ file                │\n",
       "╞═════════════════════╡\n",
       "│ an-ideal-family.txt │\n",
       "│ at-the-bay.txt      │\n",
       "│ bank-holiday.txt    │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "corpus = Corpus().load(f'{save_path}/garden-party.corpus')\n",
    "display(pl.scan_parquet(f'{corpus.corpus_path}/metadata.parquet').head(3).collect(engine='streaming'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfafa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
