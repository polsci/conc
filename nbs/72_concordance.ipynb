{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concordance\n",
    "\n",
    "> Functionality for concordance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import math\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from conc.corpus import Corpus\n",
    "from conc.result import Result\n",
    "from conc.core import logger, PAGE_SIZE, EOF_TOKEN_STR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Concordance:\n",
    "\t\"\"\" Class for concordancing. \"\"\"\n",
    "\tdef __init__(self,\n",
    "\t\t\t  corpus:Corpus # Corpus instance\n",
    "\t\t\t  ): \n",
    "\t\tself.corpus = corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@patch\n",
    "def _get_concordance_sort(self:Concordance, \n",
    "\t\t\t\t\t\t token_index: list[np.ndarray], # token index to get sort columns for\n",
    "\t\t\t\t\t\t sort_columns: list # sort columns to use\n",
    "\t\t\t\t\t\t ) -> tuple[np.ndarray, np.ndarray]: # token ids for first sort column and corresponding sort order\n",
    "\t\"\"\" Get the first sort column for a concordance. \"\"\"\n",
    "\n",
    "\tstart_time = time.time()\n",
    "\tindex = 'orth_index'\n",
    "\tseq = np.array(token_index[0]+sort_columns[0])\n",
    "\tsort_column_ids = getattr(self.corpus, index)[seq]\n",
    "\tsort_column_order = self.corpus.token_ids_to_sort_order(sort_column_ids)\n",
    "\tlogger.info(f'Concordance sort column ({sort_column_ids.shape[0]}) retrieval time: {(time.time() - start_time):.5f} seconds')\n",
    "\treturn sort_column_ids, sort_column_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "path_to_corpus_file = '../test-corpora/saved/brown.corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the corpus\n",
    "brown = Corpus('brown').load(path_to_corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the Concordance class\n",
    "report_brown = Concordance(brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29064 38309 33838 15829]\n",
      "['license' '.' 'owners' 'catchers']\n",
      "[29512    40 36157  9356]\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "token_str = 'dog'\n",
    "brown_token_sequence, brown_index_id = brown.tokenize(token_str, simple_indexing=True)\n",
    "brown_token_index = brown.get_token_index(brown_token_sequence, brown_index_id)\n",
    "\n",
    "sort_column_ids, sort_column_order = report_brown._get_concordance_sort(brown_token_index, [1, 2, 3])\n",
    "print(sort_column_ids[:4])\n",
    "print(brown.token_ids_to_tokens(sort_column_ids)[:4])\n",
    "print(sort_column_order[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def concordance(self: Concordance, \n",
    "\t\t\t\ttoken_str: str, # token string to get concordance for \n",
    "\t\t\t\tcontext_words:int = 5, # number of words to show on left and right of token string\n",
    "\t\t\t\torder:str='1R2R3R', # order of sort columns\n",
    "\t\t\t\tpage_size:int=PAGE_SIZE, # number of results to display per results page\n",
    "\t\t\t\tpage_current:int=0, # current page of results\n",
    "\t\t\t\tshow_all_columns:bool = False, # df with all columns or just essentials\n",
    "\t\t\t\tuse_cache:bool = True # retrieve the results from cache if available\n",
    "\t\t\t\t) -> Result: # concordance report results\n",
    "\t\"\"\" Report concordance for a token string. \"\"\"\n",
    "\n",
    "\t# handled output from get concordance that returns columnar format rather than rowwise\n",
    "\t# shifted to polars dataframes \n",
    "\t# make sure clean out Corpus.EOF_TOKEN from left and right\n",
    "\t# removed x*y iteration (is very slow) for getting tokens - apply vectorized method\n",
    "\t# TODO: improve ordering so not fixed options e.g. include 3R1R2R\n",
    "\t# TODO add in ordering by metadata columns or doc\n",
    "\t# DONE - reducing data retrieved to just the sort columns and then doing the concordance display separately here\n",
    "\t# DONE - could speed up the sort so that does a partial sort (e.g. just one or two columns) to get position of the slice - then handle ordering with smaller slice of data\n",
    "\t# e.g. if concordancing 'the' find what sort0 word is before start of that page and what word after - then return that slice and sort that slice only  \n",
    "\t# IDEA: potentially get sort columns until small enough result\n",
    "\t# TODO: look at retrieval of document_ids - use token2doc_index\n",
    "\t# TODO avoid any duplication related to retrieval of concordance vectors\n",
    "\n",
    "\ttoken_sequence, index_id = self.corpus.tokenize(token_str, simple_indexing=True)\n",
    "\n",
    "\tstart_time = time.time()\n",
    "\tsequence_len = len(token_sequence[0])\n",
    "\tconcordance_range = range(-1 * context_words, context_words + sequence_len)\n",
    "\tpositional_columns = [str(x) for x in concordance_range]\n",
    "\n",
    "\tindex = 'orth_index'\n",
    "\n",
    "\tcache_id = tuple(['concordance'] + list(token_sequence) + [order])\n",
    "\n",
    "\tif use_cache == True and cache_id in self.corpus.results_cache:\n",
    "\t\tlogger.info('Using cached concordance results')\n",
    "\t\tpositional_columns = self.corpus.results_cache[cache_id][0]\n",
    "\t\tconcordance_df = self.corpus.results_cache[cache_id][1]\n",
    "\t\ttotal_count = self.corpus.results_cache[cache_id][2]\n",
    "\t\ttotal_docs = self.corpus.results_cache[cache_id][3]\n",
    "\t\tsort_columns = self.corpus.results_cache[cache_id][4]\n",
    "\telse:\n",
    "\t\tlogger.info('Processing concordance results')\n",
    "\t\ttoken_index = self.corpus.get_token_index(token_sequence, index_id)\n",
    "\n",
    "\t\tif len(token_index[0]) == 0:\n",
    "\t\t\tlogger.info('No tokens found')\n",
    "\t\t\treturn None, {}, []\n",
    "\n",
    "\t\tif order == '1L2L3L':\n",
    "\t\t\tsort_columns = [-1,-2,-3]\n",
    "\t\telif order == '3L2L1L':\n",
    "\t\t\tsort_columns = [-3,-2,-1]\n",
    "\t\telif order == '2L1L1R':\n",
    "\t\t\tsort_columns = [-2,-1,sequence_len + 1 - 1]\n",
    "\t\telif order == '1L1R2R':\n",
    "\t\t\tsort_columns = [-1,sequence_len + 1 - 1,sequence_len + 2 - 1]\n",
    "\t\telse:\n",
    "\t\t\t# i.e. 1R2R3R\n",
    "\t\t\tsort_columns = [sequence_len + 1 - 1,sequence_len + 2 - 1,sequence_len + 3 - 1]\n",
    "\n",
    "\t\t# getting first sort column here\n",
    "\t\tsort_column_ids, sort_column_order = self._get_concordance_sort(token_index, sort_columns)\n",
    "\t\t\n",
    "\t\tconcordance_df = pl.DataFrame([pl.Series(name='index', values=token_index[0]), pl.Series(name='sort0', values=sort_column_order), pl.Series(name=str(sort_columns[0]), values=sort_column_ids)])\n",
    "\t\tconcordance_df = concordance_df.sort('sort0')\n",
    "\t\tconcordance_df = concordance_df.with_row_index('row')\n",
    "\n",
    "\t\ttotal_count = len(concordance_df)\n",
    "\t\ttotal_docs = len(np.unique(self.corpus.token2doc_index[np.array(token_index[0])]))\n",
    "\n",
    "\t\tself.corpus.results_cache[cache_id] = [positional_columns, concordance_df, total_count, total_docs, sort_columns]\n",
    "\n",
    "\t# working out relevant slice to populate \n",
    "\tresultset_start = page_size*page_current\n",
    "\tresultset_len = page_size\n",
    "\tresultset_end = min(resultset_start + resultset_len, len(concordance_df) - 1)\n",
    "\t\n",
    "\tstart_order = concordance_df['sort0'][resultset_start]\n",
    "\tend_order = concordance_df['sort0'][resultset_end]\n",
    "\tstart_order_pos = concordance_df.filter(pl.col(\"sort0\") == start_order).head(1)['row'].item()\n",
    "\tend_order_pos = concordance_df.filter(pl.col(\"sort0\") == end_order).tail(1)['row'].item()\n",
    "\t\n",
    "\t# populating a smaller chunk of the concordance report - as only need to retrieve/sort a subset\n",
    "\tconcordance_result_df = concordance_df.slice(start_order_pos, end_order_pos - start_order_pos + 1)\n",
    "\n",
    "\tresults_start_time = time.time()\n",
    "\tconcordance_columns = []\n",
    "\tseq = concordance_result_df['index'].to_numpy()\n",
    "\tfor pos in concordance_range:\n",
    "\t\ttokens = getattr(self.corpus, index)[np.array(seq+pos)]\n",
    "\t\tconcordance_columns.append(pl.Series(name=str(pos), values=tokens))\n",
    "\t\tif pos in sort_columns:\n",
    "\t\t\tcolumn_name = 'sort'+str(sort_columns.index(pos))\n",
    "\t\t\tif column_name != 'sort0':\n",
    "\t\t\t\tconcordance_columns.append(pl.Series(name=column_name, values=self.corpus.token_ids_to_sort_order(tokens)))\n",
    "\tlogger.info(f'Concordance results ({len(concordance_columns[0])}) retrieval time: {(time.time() - results_start_time):.5f} seconds')\n",
    "\n",
    "\tconcordance_result_df = concordance_result_df.with_columns(concordance_columns)\n",
    "\toffsets_arr = np.array(self.corpus.offsets,dtype=np.uint64)\n",
    "\tdocument_ids = np.searchsorted(offsets_arr, concordance_result_df['index'], side = 'right') - 1\n",
    "\tconcordance_result_df = concordance_result_df.with_columns(pl.Series(name=\"document_id\", values=document_ids))\n",
    "\tconcordance_result_df = concordance_result_df.sort(['sort0','sort1','sort2'])\n",
    "\t\t\n",
    "\t# slicing this further to get only the required page of results and then populating with left, keyword, right strings\n",
    "\tconcordance_view_df = concordance_result_df.slice(start_order_pos - resultset_start, page_size)\n",
    "\n",
    "\tconcordance_left = []\n",
    "\tconcordance_right = []\n",
    "\tconcordance_keyword = []\n",
    "\n",
    "\tfor pos in positional_columns:\n",
    "\t\tif int(pos) < 0:\n",
    "\t\t\tconcordance_left.append(self.corpus.token_ids_to_tokens(concordance_view_df[str(pos)]))\n",
    "\t\telif int(pos) == 0 or int(pos) < sequence_len:\n",
    "\t\t\tconcordance_keyword.append(self.corpus.token_ids_to_tokens(concordance_view_df[str(pos)]))\n",
    "\t\telse:\n",
    "\t\t\tconcordance_right.append(self.corpus.token_ids_to_tokens(concordance_view_df[str(pos)]))\n",
    "\n",
    "\tconcordance_left = [(' '.join(column)).split(EOF_TOKEN_STR)[-1] for column in np.array(concordance_left).T]\n",
    "\tconcordance_keyword = [' '.join(column) for column in np.array(concordance_keyword).T]\n",
    "\tconcordance_right = [(' '.join(column)).split(EOF_TOKEN_STR)[0] for column in np.array(concordance_right).T]\n",
    "\n",
    "\tconcordance_view_df = concordance_view_df.with_columns(pl.Series(name=\"left\", values=concordance_left), pl.Series(name=\"keyword\", values=concordance_keyword), pl.Series(name=\"right\", values=concordance_right))\n",
    "\n",
    "\ttotal_pages = math.ceil(total_count/page_size)\n",
    "\tsummary_data = {'total_count': total_count, 'total_docs': total_docs, 'page': page_current, 'total_pages': total_pages}\n",
    "\tformatted_data = [f'Total Concordance Rows: {total_count}', f'Total Documents: {total_docs}', f'Showing {min(page_size, total_count)} rows', f'Page {page_current+1} of {total_pages}']\n",
    "\n",
    "\tif show_all_columns == False:\n",
    "\t\tconcordance_view_df = concordance_view_df[['document_id', 'left', 'keyword', 'right']]\n",
    "\t\n",
    "\tlogger.info(f'Concordance report time: {(time.time() - start_time):.5f} seconds')\n",
    "\n",
    "\treturn Result(type = 'concordance', df=concordance_view_df, title=f'Concordance for \"{token_str}\"', description=f'Context tokens: {context_words}, Order: {order}', summary_data=summary_data, formatted_data=formatted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"zohtvmhkng\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n",
       "<style>\n",
       "#zohtvmhkng table {\n",
       "          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n",
       "          -webkit-font-smoothing: antialiased;\n",
       "          -moz-osx-font-smoothing: grayscale;\n",
       "        }\n",
       "\n",
       "#zohtvmhkng thead, tbody, tfoot, tr, td, th { border-style: none; }\n",
       " tr { background-color: transparent; }\n",
       "#zohtvmhkng p { margin: 0; padding: 0; }\n",
       " #zohtvmhkng .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: 0; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n",
       " #zohtvmhkng .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n",
       " #zohtvmhkng .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n",
       " #zohtvmhkng .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n",
       " #zohtvmhkng .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n",
       " #zohtvmhkng .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n",
       " #zohtvmhkng .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n",
       " #zohtvmhkng .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n",
       " #zohtvmhkng .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n",
       " #zohtvmhkng .gt_column_spanner_outer:first-child { padding-left: 0; }\n",
       " #zohtvmhkng .gt_column_spanner_outer:last-child { padding-right: 0; }\n",
       " #zohtvmhkng .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n",
       " #zohtvmhkng .gt_spanner_row { border-bottom-style: hidden; }\n",
       " #zohtvmhkng .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n",
       " #zohtvmhkng .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n",
       " #zohtvmhkng .gt_from_md> :first-child { margin-top: 0; }\n",
       " #zohtvmhkng .gt_from_md> :last-child { margin-bottom: 0; }\n",
       " #zohtvmhkng .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n",
       " #zohtvmhkng .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n",
       " #zohtvmhkng .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n",
       " #zohtvmhkng .gt_row_group_first td { border-top-width: 2px; }\n",
       " #zohtvmhkng .gt_row_group_first th { border-top-width: 2px; }\n",
       " #zohtvmhkng .gt_striped { background-color: rgba(128,128,128,0.05); }\n",
       " #zohtvmhkng .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n",
       " #zohtvmhkng .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n",
       " #zohtvmhkng .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n",
       " #zohtvmhkng .gt_left { text-align: left; }\n",
       " #zohtvmhkng .gt_center { text-align: center; }\n",
       " #zohtvmhkng .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n",
       " #zohtvmhkng .gt_font_normal { font-weight: normal; }\n",
       " #zohtvmhkng .gt_font_bold { font-weight: bold; }\n",
       " #zohtvmhkng .gt_font_italic { font-style: italic; }\n",
       " #zohtvmhkng .gt_super { font-size: 65%; }\n",
       " #zohtvmhkng .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n",
       " #zohtvmhkng .gt_asterisk { font-size: 100%; vertical-align: 0; }\n",
       " \n",
       "</style>\n",
       "<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n",
       "<thead>\n",
       "\n",
       "  <tr class=\"gt_heading\">\n",
       "    <td colspan=\"4\" class=\"gt_heading gt_title gt_font_normal\">Concordance for &quot;cause&quot;</td>\n",
       "  </tr>\n",
       "  <tr class=\"gt_heading\">\n",
       "    <td colspan=\"4\" class=\"gt_heading gt_subtitle gt_font_normal gt_bottom_border\">Context tokens: 10, Order: 1R2R3R</td>\n",
       "  </tr>\n",
       "<tr class=\"gt_col_headings\">\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Document Id\">Document Id</th>\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Left\">Left</th>\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Keyword\">Keyword</th>\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Right\">Right</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody class=\"gt_table_body\">\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">86</td>\n",
       "    <td class=\"gt_row gt_right\">abstract principle connected with it -- such as ` `</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">'' . all practical purposes , the West stands disunited</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">195</td>\n",
       "    <td class=\"gt_row gt_right\">to stand or fall only by the merits of my</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">'' . seven recognized that independence was but the first</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">99</td>\n",
       "    <td class=\"gt_row gt_right\">professionals '' but agitators for some kind of ` `</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">'' or ` ` reform '' , and this was</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">206</td>\n",
       "    <td class=\"gt_row gt_right\">he really wants is to find ` ` a sacred</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">'' to which he can honestly devote himself . restless</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">262</td>\n",
       "    <td class=\"gt_row gt_right\">` of '' that lost ` ` and '' dying</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">, ` ` and in the '' ` ` sprung</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">199</td>\n",
       "    <td class=\"gt_row gt_right\">things happening in the earth and sky with no discernable</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">, and these they attribute to the will of God</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">287</td>\n",
       "    <td class=\"gt_row gt_right\">sign the request , because of illness or other good</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">, another person who stands in close personal or business</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">252</td>\n",
       "    <td class=\"gt_row gt_right\">not be at any fault for money for prosecuting the</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">, for himself will procure it and lay it down</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">75</td>\n",
       "    <td class=\"gt_row gt_right\">short views -- only up to lunchtime '' . the</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">, his mood in the fifties rarely rises above the</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">239</td>\n",
       "    <td class=\"gt_row gt_right\"> Mando , pleading her</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">, must have said that Dr. Brown was the most</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">130</td>\n",
       "    <td class=\"gt_row gt_right\">have already been noted but no one had determined the</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">- and - effect relationship between these two primary forces</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">257</td>\n",
       "    <td class=\"gt_row gt_right\">the assumptions that man can master the principles of this</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">- and - effect universe and that such mastery will</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">410</td>\n",
       "    <td class=\"gt_row gt_right\">dreamed of all the trouble that young man would eventually</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">-- \n",
       "\n",
       "\t Of course , there was another factor .</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">357</td>\n",
       "    <td class=\"gt_row gt_right\">charm the man she loves into serving her country 's</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">-- and their tactics are much the same . begins</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">259</td>\n",
       "    <td class=\"gt_row gt_right\">no longer linked with the triumph or defeat of any</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">-- whether that of an individual assertion of the will</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">101</td>\n",
       "    <td class=\"gt_row gt_right\">'s techniques as they sought to win adherents to the</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">. contributed to the anti - slavery convictions of such</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">101</td>\n",
       "    <td class=\"gt_row gt_right\">convert , he devoted himself to the anti - slavery</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">. group of young men influenced by him enrolled in</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">163</td>\n",
       "    <td class=\"gt_row gt_right\">does not prevent the government from unqualifiedly espousing the American</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">. in Europe have our lines remained firm -- and</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">188</td>\n",
       "    <td class=\"gt_row gt_right\">means , men commonly disagree over the justice of the</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">. makes necessary a morality of means , and principles</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_right\">247</td>\n",
       "    <td class=\"gt_row gt_right\">equally baffled , attributed their difficulties to a more immediate</td>\n",
       "    <td class=\"gt_row gt_center\">cause</td>\n",
       "    <td class=\"gt_row gt_left\">. was Boniface 's monumental tactlessness . Tact '' ,</td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "  <tfoot class=\"gt_sourcenotes\">\n",
       "  \n",
       "  <tr>\n",
       "    <td class=\"gt_sourcenote\" colspan=\"4\">Total Concordance Rows: 131</td>\n",
       "  </tr>\n",
       "\n",
       "\n",
       "  <tr>\n",
       "    <td class=\"gt_sourcenote\" colspan=\"4\">Total Documents: 99</td>\n",
       "  </tr>\n",
       "\n",
       "\n",
       "  <tr>\n",
       "    <td class=\"gt_sourcenote\" colspan=\"4\">Showing 20 rows</td>\n",
       "  </tr>\n",
       "\n",
       "\n",
       "  <tr>\n",
       "    <td class=\"gt_sourcenote\" colspan=\"4\">Page 1 of 7</td>\n",
       "  </tr>\n",
       "\n",
       "</tfoot>\n",
       "\n",
       "</table>\n",
       "\n",
       "</div>\n",
       "        "
      ]
     },
     "metadata": {
      "text/html": {
       "text/html": {
        "isolated": true
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report_brown.concordance('cause', context_words = 10, order='1R2R3R').display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
