{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from conc.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conc\n",
    "\n",
    "> A Python library for efficient corpus analysis, enabling corpus linguistic analysis in Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Conc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conc is a Python library that brings corpus linguistic analysis to [Jupyter notebooks](https://docs.jupyter.org/en/latest/). A staple of data science, [Jupyter notebooks are a great model for presenting analysis](https://docs.jupyter.org/en/latest/#what-is-a-notebook) through an interactive form that combines code, reporting and discussion that allows other researchers to reproduce and interact with your analysis. Conc aims to allow researchers to analyse large corpora in efficient ways using standard hardware, with the ability to produce clear, publication-ready reports and extend analysis where required using standard Python libraries.\n",
    "\n",
    "Conc uses [spaCy](https://spacy.io/) for tokenising texts. SpaCy functionality to annotate texts will be supported soon.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conc Principles  \n",
    "\n",
    "* use standard Python libraries for data processing, analysis and visualisation (i.e. [Numpy](https://numpy.org/), [Scipy](https://scipy.org/), [Polars](https://pola.rs), [Plotly](https://plotly.com/python/))\n",
    "* use vector operations where possible  \n",
    "* use fast code libraries and fast data structures (i.e. Conc uses [Polars vs Pandas](https://pola.rs/posts/benchmarks/) - you can still output Pandas dataframes if you want to use them)  \n",
    "* provide clear and complete information when reporting results  \n",
    "* pre-compute time-intensive and repeatedly used views of the data  \n",
    "* work with smaller slices of the data where possible  \n",
    "* cache specific anaysis during a session to reduce computation for repeated calls  \n",
    "* [document corpus representations so that they can be worked with directly](https://geoffford.nz/conc/anatomy.html)  \n",
    "* allow researchers to work with Conc results and extend analysis using other Python libraries  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Acknowledgements](#acknowledgements)  \n",
    "* [Development Status](#development-status)  \n",
    "* [Installation](#installation)  \n",
    "    * [Install via pip](#install-via-pip)  \n",
    "    * [Install a spaCy model for tokenization](#install-a-spacy-model-for-tokenization)  \n",
    "    * [Install optional dependencies](#install-optional-dependencies)  \n",
    "    * [Pre-2013 CPU? Install Polars with support for older machines](#pre-2013-cpu-install-polars-with-support-for-older-machines)  \n",
    "* [Using Conc](#using-conc)  \n",
    "* [Roadmap](#roadmap)  \n",
    "* [Developer Guide](#developer-guide)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conc is developed by [Dr Geoff Ford](https://geoffford.nz/).\n",
    "\n",
    "Conc originated in my PhD research, which included development of a web-based corpus browser to handle analysis of large corpora. I've been developing Conc through my subsequent research.  \n",
    "\n",
    "Work to create this Python library has been made possible by funding/support from:  \n",
    "\n",
    "- \"Mapping LAWS: Issue Mapping and Analyzing the Lethal Autonomous Weapons Debate\" (Royal Society of New Zealand’s Marsden Fund Grant 19-UOC-068)  \n",
    "- \"Into the Deep: Analysing the Actors and Controversies Driving the Adoption of the World’s First Deep Sea Mining Governance\" (Royal Society of New Zealand’s Marsden Fund Grant 22-UOC-059)\n",
    "- Sabbatical, University of Canterbury, Semester 1 2025.  \n",
    "\n",
    "Thanks to the Mapping LAWS project team for their support and feedback as first users of ConText (a web-based application built on an earlier version of Conc).  \n",
    "\n",
    "Dr Ford is a researcher with [Te Pokapū Aronui ā-Matihiko | UC Arts Digital Lab (ADL)](https://artsdigitallab.canterbury.ac.nz/). Thanks to the ADL team and the ongoing support of the University of Canterbury's Faculty of Arts who make work like this possible.  \n",
    "\n",
    "Thanks to Dr Chris Thomson and Karin Stahel for their feedback on early versions of Conc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conc is in active development. It is currently [released][pypi] for beta testing. The Github site may be ahead of the Pypi version, so for latest functionality install from Github (see below). The Github code is pre-release and may change. For the latest release, install from Pypi (`pip install conc`). The [documentation][docs] reflects the most recent functionality. See the [CHANGELOG][changelog] for notes on releases and the Roadmap below for upcoming features.  \n",
    "\n",
    "[repo]: https://github.com/polsci/conc\n",
    "[docs]: https://geoffford.nz/conc/\n",
    "[pypi]: https://pypi.org/project/conc/\n",
    "[changelog]: https://github.com/polsci/conc/blob/main/CHANGELOG.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install via pip\n",
    "\n",
    "You can install Conc from [pypi][pypi] using this command:   \n",
    "\n",
    "```sh\n",
    "$ pip install conc\n",
    "```\n",
    "\n",
    "To install the latest development version of Conc, which may be ahead of the version on Pypi, you can install from the [repository][repo]:  \n",
    "\n",
    "```sh\n",
    "$ pip install git+https://github.com/polsci/conc.git\n",
    "```\n",
    "\n",
    "### Install a spaCy model for tokenization\n",
    "\n",
    "The first releases of Conc require a SpaCy language model for tokenization. After installing Conc, install a model. Here's an example of how to install SpaCy's small English model, which is Conc's default language model:  \n",
    "\n",
    "```sh\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "If you are working with a different language or want to use a different 'en' model, check the [SpaCy models documentation](https://spacy.io/models/) for the relevant model name.\n",
    "\n",
    "### Install optional dependencies\n",
    "\n",
    "Conc has some optional dependencies you can install to download source texts to create sample corpora. These are primarily intended for creating corpora for development. To minimize Conc's requirements these are not installed by default. If you want to get sample corpora to test out Conc's functionality you can install these with the following command. \n",
    "\n",
    "```sh\n",
    "$ pip install nltk requests datasets\n",
    "```\n",
    "\n",
    "[repo]: https://github.com/polsci/conc\n",
    "[docs]: https://geoffford.nz/conc/\n",
    "[pypi]: https://pypi.org/project/conc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-2013 CPU? Install Polars with support for older machines\n",
    "\n",
    "Polars is optimized for modern CPUs with support for AVX2 instructions. If you get kernel crashes running Conc on an older machine (probably pre-2013), this is likely to be an issue with Polars. Polars has an [alternate installation option to support older machines](https://docs.pola.rs/user-guide/installation/), which installs a Polars build compiled without AVX2 support. Replace the standard Polars package with the legacy-support package to use Conc on older machines.\n",
    "\n",
    "```sh\n",
    "$ pip uninstall polars\n",
    "$ pip install polars-lts-cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Conc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good place to start is TODO, which demonstrates how to build a corpus and output Conc reports.   \n",
    "\n",
    "The [documentation site][docs] provides a reference for Conc functionality and examples of how to create reports for analysis. The current Conc components are listed below. \n",
    "\n",
    "[repo]: https://github.com/polsci/conc\n",
    "[docs]: https://geoffford.nz/conc/\n",
    "[pypi]: https://pypi.org/project/conc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Class / Function | Module | Functionality | Note |\n",
    "| -------- | ------- | ------- | ------- |\n",
    "| `Corpus` | conc.corpus | Build and load and get information on a corpus, methods to work with a corpus | Required |\n",
    "| `Conc` | conc.conc | Inferface to Conc reports for corpus analysis | Recommended way to access reports for analysis, requires a corpus created by Corpus module |\n",
    "| `Text` | conc.text |Output text from the corpus | Access via Corpus |\n",
    "| `Frequency` | conc.frequency | Frequency reporting | Access via Conc |\n",
    "| `Ngrams` | conc.ngrams | Reporting on `ngram_frequencies` across corpus and `ngrams` containing specific tokens | Access via Conc |\n",
    "| `Concordance` | conc.concordance | Concordancing | Access via Conc |\n",
    "| `Keyness` | conc.keyness | Reporting for keyness analysis | Access via Conc |\n",
    "| `Collocates` | conc.collocates | Reporting for collocation analysis | Access via Conc |\n",
    "| `Result` | conc.result | Handles report results, output result as table or get dataframe | Used by all reports |\n",
    "| `ConcLogger` | conc.core | Logger | Logging implemented in all modules |\n",
    "| `CorpusMetadata` | conc.core | Class to validate Corpus Metadata JSON | Used by Corpus class |\n",
    "\n",
    "The conc.core module implements a number of helpful functions ...\n",
    "\n",
    "| Function | Functionality |\n",
    "| -------- | ------- |\n",
    "| `list_corpora` | Scan a directory for corpora and return a summary |\n",
    "| `get_stop_words` | Get a spaCy stop word list list for a specific model |\n",
    "| Various - see `Get data sources` | Functions to download source texts to create sample corpora. Primarily intended for development/testing. To minimize requirements not all libraries are installed by default. Functions will raise errors with information on installing required libraries. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "### Short-term\n",
    "\n",
    "- [ ] add tutorial/walkthrough/ getting started notebook\n",
    "- [ ] add citation information\n",
    "- [ ] document use of Conc results in other Python libraries (e.g. Pandas) via tutorial/walkthrough, results module (include link on README principles) \n",
    "- [ ] Corpus tokenize support for functionality from earlier versions of Conc for wildcards, multiple strings, case insensitive tokenization\n",
    "- [ ] extend caching support to all intensive reports, revise storage of cached results for in-memory/disk option\n",
    "- [ ] relegate some logger warnings to debug level and audit logger messages for consistency and clarity for users\n",
    "- [ ] add support for build from datasets library\n",
    "- [ ] ngrams method - implement case handling\n",
    "- [ ] get_ngrams_by_index - implement case handling\n",
    "- [ ] improve concordance ordering so not fixed options e.g. include 3R1R2R\n",
    "- [ ] improve ngram support for ngram token position beyond LEFT/RIGHT (i.e. define positions relative to ngram, or ANY)\n",
    "- [ ] concordancing - add in ordering by metadata columns or doc\n",
    "- [ ] annotations support for spaCy POS, TAG, SENT_START, LEMMA \n",
    "- [ ] shift more processing from in-memory to polars with support for streaming or in-memory processing\n",
    "- [ ] revisit polars streaming - potentially implement a batched write for very large files i.e. splitting vocab/tokens files into smaller chunks to reduce memory usage.\n",
    "\n",
    "### Medium-term\n",
    "\n",
    "- [ ] Support for processing backends other than spaCy (i.e. other tokenizers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instructions below are only relevant if you want to contribute to Conc. The [nbdev](https://nbdev.fast.ai/) library is being used for development. If you are new to using nbdevc, here are some useful pointers to get you started (or visit the [nbdev website](https://nbdev.fast.ai/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install conc in Development mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# make sure conc package is installed in development mode\n",
    "$ pip install -e .\n",
    "\n",
    "# make changes under nbs/ directory\n",
    "# ...\n",
    "\n",
    "# compile to have changes apply to conc\n",
    "$ nbdev_prepare\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
