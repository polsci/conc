{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keyness\n",
    "\n",
    "> Functionality for keyness analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp keyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import time\n",
    "import polars as pl\n",
    "from fastcore.basics import patch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from conc.corpus import Corpus\n",
    "from conc.result import Result\n",
    "from conc.core import logger, PAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Keyness:\n",
    "\t\"\"\" Class for keyness analysis reporting. \"\"\"\n",
    "\tdef __init__(self,\n",
    "\t\t\t  corpus:Corpus # Corpus instance\n",
    "\t\t\t  ): \n",
    "\t\tself.corpus = corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version from old version of the library\n",
    "# def keywords(self:Keyness, \n",
    "# \t\t\t reference_corpus:Corpus, # Reference corpus\n",
    "# \t\t\t use_cache:bool=True # retrieve the results from cache if available\n",
    "# \t\t\t ) -> Result: # Result instance\n",
    "\t\n",
    "# \tstart_time = time.time()\n",
    "\n",
    "# \tcache_id = tuple(['keywords'])\n",
    "# \tif use_cache == True and cache_id in self.corpus.results_cache:\n",
    "# \t\tkeyness_report = self.corpus.results_cache[cache_id]\n",
    "# \telse:\n",
    "\n",
    "# \t\tminimum_reference_normalised_freq = math.log2(0.5/reference_corpus['token_count'])\n",
    "\n",
    "# \t\tnormalised_freq_in_corpus = np.array(list(loaded_corpora[corpus_name]['frequency_lookup'].values()))/loaded_corpora[corpus_name]['token_count']\n",
    "# \t\tnormalised_freq_in_reference = np.array(list(reference_corpus['frequency_lookup'].values()))/reference_corpus['token_count']\n",
    "\n",
    "# \t\tnormalised_freq_in_corpus = np.log2(normalised_freq_in_corpus)\n",
    "# \t\tnormalised_freq_in_reference = np.log2(normalised_freq_in_reference)\n",
    "\n",
    "# \t\tnormalised_freq_in_corpus = dict(zip(loaded_corpora[corpus_name]['frequency_lookup'].keys(), normalised_freq_in_corpus.tolist()))\n",
    "# \t\tnormalised_freq_in_reference = dict(zip(reference_corpus['frequency_lookup'].keys(), normalised_freq_in_reference.tolist()))\n",
    "\n",
    "# \t\tkeyness_data = {}\n",
    "# \t\tfor token_id in normalised_freq_in_corpus:\n",
    "# \t\t\tif token_id in normalised_freq_in_reference:\n",
    "# \t\t\t\tlog_ratio = normalised_freq_in_corpus[token_id] - normalised_freq_in_reference[token_id]\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tlog_ratio = normalised_freq_in_corpus[token_id] - minimum_reference_normalised_freq\n",
    "# \t\t\tkeyness_data[token_id] = {'id': loaded_corpora[corpus_name]['vocab'][token_id], 'log_ratio': log_ratio}\n",
    "\n",
    "# \t\tkeyness_report = pd.DataFrame.from_dict(keyness_data, orient='index').sort_values(['log_ratio'], ascending=False)\n",
    "\n",
    "# \t\tself.corpus.results_cache[cache_id] = keyness_report\n",
    "\n",
    "# \treturn keyness_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "path_to_brown_corpus = '../test-corpora/saved/brown.corpus'\n",
    "path_to_reuters_corpus = '../test-corpora/saved/reuters.corpus'\n",
    "path_to_gutenberg_corpus = '../test-corpora/saved/gutenberg.corpus'\n",
    "path_to_rnz_corpus = '../test-corpora/saved/rnz-10k.corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the corpus\n",
    "brown = Corpus().load(path_to_brown_corpus)\n",
    "reuters = Corpus().load(path_to_reuters_corpus)\n",
    "gutenberg = Corpus().load(path_to_gutenberg_corpus)\n",
    "rnz = Corpus().load(path_to_rnz_corpus)\n",
    "garden = Corpus().load('../test-corpora/saved/garden-party-corpus.corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.summary()\n",
    "reuters.summary()\n",
    "gutenberg.summary()\n",
    "rnz.summary()\n",
    "garden.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conc.frequency import Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_brown = Frequency(brown)\n",
    "frequencies_reuters = Frequency(reuters)\n",
    "frequencies_gutenberg = Frequency(gutenberg)\n",
    "frequencies_rnz = Frequency(rnz)\n",
    "frequences_garden = Frequency(garden)\n",
    "\n",
    "\n",
    "frequencies_brown.frequencies(normalize_by=1000000).display()\n",
    "frequencies_reuters.frequencies(normalize_by=1000000).display()\n",
    "frequencies_gutenberg.frequencies(normalize_by=1000000).display()\n",
    "frequencies_rnz.frequencies(normalize_by=1000000).display()\n",
    "frequences_garden.frequencies(normalize_by=1000000).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conc.concordance import Concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_concordance = Concordance(brown)\n",
    "reuters_concordance = Concordance(reuters)\n",
    "gutenberg_concordance = Concordance(gutenberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = brown\n",
    "target = garden\n",
    "\n",
    "reference_df = reference.frequency_table.sort('frequency', descending=True).filter(pl.col('is_punct') == False).filter(pl.col('is_space') == False)\n",
    "target_df = target.frequency_table.sort('frequency', descending=True).filter(pl.col('is_punct') == False).filter(pl.col('is_space') == False)\n",
    "# create new pl df joined by token\n",
    "reference_min_freq = 0.05 * 1000000 / reference.word_token_count\n",
    "target_min_freq = 0.05 * 1000000 / target.word_token_count\n",
    "combined_frequency_table = target_df.join(reference_df, on='token', how='left', suffix = '_reference').drop('rank', 'token_id', 'is_punct', 'is_space', 'rank_reference', 'token_id_reference', 'is_punct_reference', 'is_space_reference')\n",
    "\n",
    "# polars df -  replace null values in normalized_frequency_reference with the brown_min_frequency\n",
    "combined_frequency_table = combined_frequency_table.with_columns(pl.col('normalized_frequency_reference').fill_null(reference_min_freq))\n",
    "combined_frequency_table = combined_frequency_table.with_columns((pl.col('normalized_frequency')/pl.col('normalized_frequency_reference')).alias('relative_risk'))\n",
    "\n",
    "print(combined_frequency_table.filter(pl.col('frequency') > 100).sort('relative_risk', descending=True).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the Ngrams class\n",
    "report_brown = Keyness(brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
