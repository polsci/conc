{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Helper functions and classes for Conc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# requirements - numpy pandas polars spacy nltk great_tables\n",
    "# dev requirements - nbdev, jupyterlab, memory_profiler\n",
    "# TODO check all necessary\n",
    "\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "import polars as pl\n",
    "from great_tables import GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "PAGE_SIZE = 20\n",
    "EOF_TOKEN_STR = ' conc-end-of-file-token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class ConcLogger(logging.Logger):\n",
    "\t\"\"\" Custom logger for conc module. \"\"\"\n",
    "\tdef __init__(self, name, level=logging.WARNING):\n",
    "\t\tsuper().__init__(name, level)\n",
    "\t\tself._setup_handler()\n",
    "\n",
    "\tdef _setup_handler(self):\n",
    "\t\thandler = logging.StreamHandler()\n",
    "\t\tformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(funcName)s - %(message)s', \n",
    "\t\t\t\t\t\t\t\t\t  datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\t\thandler.setFormatter(formatter)\n",
    "\t\tself.addHandler(handler)\n",
    "\n",
    "\tdef set_state(self, state:str # 'quiet' or 'verbose'\n",
    "\t\t\t\t  ):\n",
    "\t\tif state == 'quiet':\n",
    "\t\t\tlevel = logging.WARNING\n",
    "\t\telif state == 'verbose':\n",
    "\t\t\tlevel = logging.INFO\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"Invalid state: {state}\")\n",
    "\t\t\n",
    "\t\tself.setLevel(level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "logging.setLoggerClass(ConcLogger)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def set_logger_state(state:str # 'quiet' or 'verbose'\n",
    "\t\t\t\t\t ):\n",
    "\t\"\"\" Set the state of the conc logger to either 'quiet' or 'verbose' \"\"\"\n",
    "\tlogger.set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "toy_data = []\n",
    "toy_data.append(['1.txt', 'The cat sat on the mat.', 'feline', 'cat'])\n",
    "toy_data.append(['2.txt', 'The dog sat on the mat.', 'canine', 'dog'])\n",
    "toy_data.append(['3.txt', 'The cat is meowing.', 'feline', 'cat'])\n",
    "toy_data.append(['4.txt', 'The dog is barking.', 'canine', 'dog'])\n",
    "toy_data.append(['5.txt', 'The cat is climbing a tree.', 'feline', 'cat'])\n",
    "toy_data.append(['6.txt', 'The dog is digging a hole.', 'canine', 'dog'])\n",
    "\n",
    "source_path = '../test-corpora/source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_toy_corpus_sources(source_path:str # patch to location of sources for building corpora\n",
    "\t\t\t\t\t\t\t ):\n",
    "\t\"\"\" Create txt files and csv to test build of toy corpus. \"\"\"\n",
    "\n",
    "\ttoy_path = os.path.join(source_path, 'toy')\n",
    "\tif not os.path.exists(toy_path):\n",
    "\t\tos.makedirs(toy_path, exist_ok=True)\n",
    "\tfor row in toy_data:\n",
    "\t\twith open(os.path.join(source_path, 'toy', row[0]), 'w', encoding='utf-8') as f:\n",
    "\t\t\tf.write(row[1])\n",
    "\tdf = pl.DataFrame(toy_data, orient='row', schema=(('source', str), ('text', str), ('category', str), ('species', str)))\n",
    "\tdf.write_csv(os.path.join(source_path, 'toy.csv'))\n",
    "\tdf.write_csv(os.path.join(source_path, 'toy.csv.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "create_toy_corpus_sources(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"geffzogmwh\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n",
       "<style>\n",
       "#geffzogmwh table {\n",
       "          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n",
       "          -webkit-font-smoothing: antialiased;\n",
       "          -moz-osx-font-smoothing: grayscale;\n",
       "        }\n",
       "\n",
       "#geffzogmwh thead, tbody, tfoot, tr, td, th { border-style: none; }\n",
       " tr { background-color: transparent; }\n",
       "#geffzogmwh p { margin: 0; padding: 0; }\n",
       " #geffzogmwh .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: 0; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n",
       " #geffzogmwh .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n",
       " #geffzogmwh .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n",
       " #geffzogmwh .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n",
       " #geffzogmwh .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n",
       " #geffzogmwh .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n",
       " #geffzogmwh .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n",
       " #geffzogmwh .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n",
       " #geffzogmwh .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n",
       " #geffzogmwh .gt_column_spanner_outer:first-child { padding-left: 0; }\n",
       " #geffzogmwh .gt_column_spanner_outer:last-child { padding-right: 0; }\n",
       " #geffzogmwh .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n",
       " #geffzogmwh .gt_spanner_row { border-bottom-style: hidden; }\n",
       " #geffzogmwh .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n",
       " #geffzogmwh .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n",
       " #geffzogmwh .gt_from_md> :first-child { margin-top: 0; }\n",
       " #geffzogmwh .gt_from_md> :last-child { margin-bottom: 0; }\n",
       " #geffzogmwh .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n",
       " #geffzogmwh .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n",
       " #geffzogmwh .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n",
       " #geffzogmwh .gt_row_group_first td { border-top-width: 2px; }\n",
       " #geffzogmwh .gt_row_group_first th { border-top-width: 2px; }\n",
       " #geffzogmwh .gt_striped { background-color: rgba(128,128,128,0.05); }\n",
       " #geffzogmwh .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n",
       " #geffzogmwh .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n",
       " #geffzogmwh .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n",
       " #geffzogmwh .gt_left { text-align: left; }\n",
       " #geffzogmwh .gt_center { text-align: center; }\n",
       " #geffzogmwh .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n",
       " #geffzogmwh .gt_font_normal { font-weight: normal; }\n",
       " #geffzogmwh .gt_font_bold { font-weight: bold; }\n",
       " #geffzogmwh .gt_font_italic { font-style: italic; }\n",
       " #geffzogmwh .gt_super { font-size: 65%; }\n",
       " #geffzogmwh .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n",
       " #geffzogmwh .gt_asterisk { font-size: 100%; vertical-align: 0; }\n",
       " \n",
       "</style>\n",
       "<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n",
       "<thead>\n",
       "\n",
       "<tr class=\"gt_col_headings\">\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"source\">source</th>\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"text\">text</th>\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"category\">category</th>\n",
       "  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"species\">species</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody class=\"gt_table_body\">\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">1.txt</td>\n",
       "    <td class=\"gt_row gt_left\">The cat sat on the mat.</td>\n",
       "    <td class=\"gt_row gt_left\">feline</td>\n",
       "    <td class=\"gt_row gt_left\">cat</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">2.txt</td>\n",
       "    <td class=\"gt_row gt_left\">The dog sat on the mat.</td>\n",
       "    <td class=\"gt_row gt_left\">canine</td>\n",
       "    <td class=\"gt_row gt_left\">dog</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">3.txt</td>\n",
       "    <td class=\"gt_row gt_left\">The cat is meowing.</td>\n",
       "    <td class=\"gt_row gt_left\">feline</td>\n",
       "    <td class=\"gt_row gt_left\">cat</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">4.txt</td>\n",
       "    <td class=\"gt_row gt_left\">The dog is barking.</td>\n",
       "    <td class=\"gt_row gt_left\">canine</td>\n",
       "    <td class=\"gt_row gt_left\">dog</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">5.txt</td>\n",
       "    <td class=\"gt_row gt_left\">The cat is climbing a tree.</td>\n",
       "    <td class=\"gt_row gt_left\">feline</td>\n",
       "    <td class=\"gt_row gt_left\">cat</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"gt_row gt_left\">6.txt</td>\n",
       "    <td class=\"gt_row gt_left\">The dog is digging a hole.</td>\n",
       "    <td class=\"gt_row gt_left\">canine</td>\n",
       "    <td class=\"gt_row gt_left\">dog</td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "\n",
       "\n",
       "</table>\n",
       "\n",
       "</div>\n",
       "        "
      ]
     },
     "metadata": {
      "text/html": {
       "text/html": {
        "isolated": true
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "toy_corpus_df = pl.read_csv(os.path.join(source_path, 'toy.csv'))\n",
    "GT(toy_corpus_df).tab_options(table_margin_left = 0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_nltk_corpus_sources(source_path:str # patch to location of sources for building corpora\n",
    "\t\t\t\t\t\t\t ):\n",
    "\t\"\"\" Get nltk corpora as sources for testing. \"\"\"\n",
    "\n",
    "\timport nltk\n",
    "\tnltk.download('gutenberg')\n",
    "\tnltk.download('brown')\n",
    "\tnltk.download('reuters')\n",
    "\tfrom nltk.corpus import gutenberg\n",
    "\tfrom nltk.corpus import reuters\n",
    "\tfrom nltk.corpus import brown\n",
    "\n",
    "\tdef clean_text(text):\n",
    "\t\t# to match words/punc that followed by /tags\n",
    "\t\tpattern = re.compile(r\"(\\S+)(/[^ ]+)\") # match non-space followed by / and non-space\n",
    "\t\treturn pattern.sub(r\"\\1\", text)\n",
    "\n",
    "\tbrown_path = os.path.join(source_path, 'brown.csv.gz')\n",
    "\tcorpus_data = []\n",
    "\tfor fileid in brown.fileids():\n",
    "\t\tcorpus_data.append([fileid, clean_text(brown.raw(fileid))])\n",
    "\t\twith open(os.path.join(source_path, 'brown', f'{fileid}.txt'), 'w', encoding='utf-8') as f:\n",
    "\t\t\tf.write(clean_text(brown.raw(fileid)))\n",
    "\tdf = pl.DataFrame(corpus_data, orient='row', schema=(('source', str), ('text', str)))\n",
    "\tdf.write_csv(brown_path)\n",
    "\n",
    "\tgutenberg_path = os.path.join(source_path, 'gutenberg.csv.gz')\n",
    "\tcorpus_data = []\n",
    "\tfor fileid in gutenberg.fileids():\n",
    "\t\tcorpus_data.append([fileid, clean_text(gutenberg.raw(fileid))])\n",
    "\tdf = pl.DataFrame(corpus_data, orient='row', schema=(('source', str), ('text', str)))\n",
    "\tdf.write_csv(gutenberg_path)\n",
    "\n",
    "\treuters_path = os.path.join(source_path, 'reuters.csv.gz')\n",
    "\tcorpus_data = []\n",
    "\tfor fileid in reuters.fileids():\n",
    "\t\tfileid_name = fileid.split('/')[1]\n",
    "\t\tcorpus_data.append([fileid_name, clean_text(reuters.raw(fileid))])\n",
    "\tdf = pl.DataFrame(corpus_data, orient='row', schema=(('source', str), ('text', str)))\n",
    "\tdf.write_csv(reuters_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/geoff/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /home/geoff/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to /home/geoff/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "get_nltk_corpus_sources(source_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts for the Brown corpus from nltk can be used for testing Conc functionality. The Reuters and Gutenberg corpora are also prepared by `get_nltk_corpus_sources`. Running the function will download the texts and save the texts as a .csv.gz files with columns: source and text. The Brown Corpus is also saved as .txt files to test the Corpus.build_from_texts method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# TODO - cleanup or move to function - creating sample data from large data-set\n",
    "# create_sample_data = False\n",
    "# if create_sample_data == True:\n",
    "# \t# load standard csv library\n",
    "# \timport csv\n",
    "# \timport gzip\n",
    "\n",
    "# \tfor max_i in [10000, 100000, 200000, 500000]:\n",
    "# \t\tmax_i_label = int(max_i / 1000)\n",
    "# \t\t# create version with just first 100000 rows\n",
    "# \t\twith gzip.open('../test-corpora/source/rnz.csv.gz', 'rt') as f:\n",
    "# \t\t\treader = csv.DictReader(f)\n",
    "# \t\t\twith gzip.open(f'../test-corpora/source/rnz-{max_i_label}k.csv.gz', 'wt') as f_out:\n",
    "# \t\t\t\twriter = csv.DictWriter(f_out, fieldnames=reader.fieldnames)\n",
    "# \t\t\t\twriter.writeheader()\n",
    "# \t\t\t\tfor i, row in enumerate(reader):\n",
    "# \t\t\t\t\tif i > max_i - 1:\n",
    "# \t\t\t\t\t\tbreak\n",
    "# \t\t\t\t\twriter.writerow(row)\n",
    "# \t\t\tprint(f'Created file rnz-{max_i_label}k.csv.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
